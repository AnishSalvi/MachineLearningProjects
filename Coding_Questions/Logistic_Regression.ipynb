{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1Xdfw_U5mS5",
        "outputId": "1cd5a36f-5d96-4c80-d398-1394f3030792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ],
      "source": [
        "#imports\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#class\n",
        "class LogisticRegression:\n",
        "\n",
        "  def __init__(self, lr = 1e-5, max_iters = 1000):\n",
        "    self.lr = lr\n",
        "    self.max_iters = max_iters\n",
        "    self.W = None\n",
        "    self.b = None\n",
        "\n",
        "  def sigmoid(self, x):\n",
        "    return (1 / (1 + np.exp(-x)))\n",
        "\n",
        "  def fit(self, x_train, y_train):\n",
        "    #fit\n",
        "    n_samples, n_features = x_train.shape\n",
        "    self.W = np.zeros(n_features)\n",
        "    self.b = np.zeros(1)\n",
        "    #iterate\n",
        "    for i in range(self.max_iters):\n",
        "      #forward\n",
        "      outputs = np.dot(x_train, self.W) + self.b\n",
        "      y_pred = self.sigmoid(outputs)\n",
        "      #grad\n",
        "      dW = (1/n_samples) * np.dot(x_train.T, (y_pred - y_train))\n",
        "      db = (1/n_samples) * np.sum(y_pred - y_train)\n",
        "      #update\n",
        "      self.W = self.W - self.lr * dW\n",
        "      self.b = self.b - self.lr * db\n",
        "\n",
        "  def predict(self, x_test):\n",
        "    #forward\n",
        "    outputs = np.dot(x_test, self.W) + self.b\n",
        "    y_pred = self.sigmoid(outputs)\n",
        "    #return\n",
        "    return np.where(y_pred > 0.5, 1, 0)\n",
        "\n",
        "#main\n",
        "iris = datasets.load_iris()\n",
        "#load data\n",
        "x = iris['data'][:100]\n",
        "#load target\n",
        "y = iris['target'][:100]\n",
        "#norm\n",
        "x = (x - x.mean(axis = 0)) / x.std(axis = 0)\n",
        "#x = (x - x.min(axis = 0)) / (x.max(axis = 0) - x.min(axis = 0))\n",
        "#get\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 42, shuffle = True, stratify = y)\n",
        "#model\n",
        "model = LogisticRegression()\n",
        "#fit\n",
        "model.fit(x_train, y_train)\n",
        "#predict\n",
        "y_pred = model.predict(x_test)\n",
        "#compute\n",
        "print((y_pred == y_test).sum() / len(y_test))"
      ]
    }
  ]
}