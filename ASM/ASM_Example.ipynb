{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2a8298545c884e2692642af82eb0065c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7fb4f214264433ca961a00857f7b61e",
              "IPY_MODEL_a3eebaf346084512b2b06743a00d8edb",
              "IPY_MODEL_04c5c1c372dd44b0bc9119f650906ad8"
            ],
            "layout": "IPY_MODEL_eef8ab40bdb54272bed2f1ca91d9ff13"
          }
        },
        "e7fb4f214264433ca961a00857f7b61e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c71530b099e4492e9febb4c2e67d0d73",
            "placeholder": "​",
            "style": "IPY_MODEL_c55acf7ac97c436ba78da128506d7307",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "a3eebaf346084512b2b06743a00d8edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4b5a34dd51e49bba7eecc0c2f44b89a",
            "max": 4186,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f98100e96244884b476ac4ba9f4b5a7",
            "value": 4186
          }
        },
        "04c5c1c372dd44b0bc9119f650906ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36a9af3a425e4f2a98d185336201099a",
            "placeholder": "​",
            "style": "IPY_MODEL_e99bc09b170a44f08e51995c3c1cce00",
            "value": " 4.19k/4.19k [00:00&lt;00:00, 285kB/s]"
          }
        },
        "eef8ab40bdb54272bed2f1ca91d9ff13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c71530b099e4492e9febb4c2e67d0d73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c55acf7ac97c436ba78da128506d7307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4b5a34dd51e49bba7eecc0c2f44b89a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f98100e96244884b476ac4ba9f4b5a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36a9af3a425e4f2a98d185336201099a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e99bc09b170a44f08e51995c3c1cce00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47ef8ced340249818293db2953421f14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3cbe5a260fc34aa79627ff85c023c727",
              "IPY_MODEL_a460434b56e94587a7eedaf6ce974b53",
              "IPY_MODEL_585f3efd8a9342578a69b47e7e4cb651"
            ],
            "layout": "IPY_MODEL_1f75ddd95f304d86bfab7b11080b3657"
          }
        },
        "3cbe5a260fc34aa79627ff85c023c727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ee83f046f204f8ba5bde9743335e921",
            "placeholder": "​",
            "style": "IPY_MODEL_445e4dfbbcbd4905b9c606d6a3fcfae4",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "a460434b56e94587a7eedaf6ce974b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3167278526aa4b0e9e995a5291d07d11",
            "max": 862328,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_149d772e6db24ebd8b404a269bff98bd",
            "value": 862328
          }
        },
        "585f3efd8a9342578a69b47e7e4cb651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b652853bf46b49c593ccf4876cc75b5f",
            "placeholder": "​",
            "style": "IPY_MODEL_9062352892064fc8b92ab7382e033a19",
            "value": " 862k/862k [00:00&lt;00:00, 5.28MB/s]"
          }
        },
        "1f75ddd95f304d86bfab7b11080b3657": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ee83f046f204f8ba5bde9743335e921": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "445e4dfbbcbd4905b9c606d6a3fcfae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3167278526aa4b0e9e995a5291d07d11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "149d772e6db24ebd8b404a269bff98bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b652853bf46b49c593ccf4876cc75b5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9062352892064fc8b92ab7382e033a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54626fc2f67d433c92ac34ba64bab08c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_357b410c119b4ec6be5b67c8854e1ea9",
              "IPY_MODEL_a380f22dcd9348208815ef37772d0b18",
              "IPY_MODEL_b30d5e60d26a42c89d0a77fbee1e86ed"
            ],
            "layout": "IPY_MODEL_349bf636bfda46ccb23fef4b894c6fbc"
          }
        },
        "357b410c119b4ec6be5b67c8854e1ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_822e6bb406714f54bd8a682453dc372f",
            "placeholder": "​",
            "style": "IPY_MODEL_7ae7261d55ab40a29d49a882fa882278",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "a380f22dcd9348208815ef37772d0b18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d39f7d07b5e4845857a4ae5e65cd9e6",
            "max": 524657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0884bdee31754ccdbf38ba22f7314027",
            "value": 524657
          }
        },
        "b30d5e60d26a42c89d0a77fbee1e86ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc4d85f1c23c46ffbb83199d432c6f54",
            "placeholder": "​",
            "style": "IPY_MODEL_62e50802898c4d5ca34562dd4c18c92e",
            "value": " 525k/525k [00:00&lt;00:00, 2.15MB/s]"
          }
        },
        "349bf636bfda46ccb23fef4b894c6fbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "822e6bb406714f54bd8a682453dc372f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ae7261d55ab40a29d49a882fa882278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d39f7d07b5e4845857a4ae5e65cd9e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0884bdee31754ccdbf38ba22f7314027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc4d85f1c23c46ffbb83199d432c6f54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62e50802898c4d5ca34562dd4c18c92e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b517aeeff6fd467897517206bbcc04c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fa5eac74ac74d43b6d50fd3638d4fb0",
              "IPY_MODEL_d6ccdfe952394a68a810ddf217211c82",
              "IPY_MODEL_efa944bcbac44f17839bc1100e9f9725"
            ],
            "layout": "IPY_MODEL_066978240f244f0b82b5eb7928ee353c"
          }
        },
        "3fa5eac74ac74d43b6d50fd3638d4fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a745393ad6e145a39fc2a8aeed8a55b4",
            "placeholder": "​",
            "style": "IPY_MODEL_1025f37b2f144bd199c612eda55c25be",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "d6ccdfe952394a68a810ddf217211c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da4048cc15d143ff925dfe4d5a49d7dd",
            "max": 389,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d18116152c548419fc4b59669b8efbe",
            "value": 389
          }
        },
        "efa944bcbac44f17839bc1100e9f9725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6901000b2ee54a79954228f8e438b69b",
            "placeholder": "​",
            "style": "IPY_MODEL_8471da42a88249669bdf9cb68074b395",
            "value": " 389/389 [00:00&lt;00:00, 19.6kB/s]"
          }
        },
        "066978240f244f0b82b5eb7928ee353c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a745393ad6e145a39fc2a8aeed8a55b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1025f37b2f144bd199c612eda55c25be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da4048cc15d143ff925dfe4d5a49d7dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d18116152c548419fc4b59669b8efbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6901000b2ee54a79954228f8e438b69b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8471da42a88249669bdf9cb68074b395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c707985689b741ebbed30fd1e2fccf49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a63ae8dab834217b154efa90ddf0fb5",
              "IPY_MODEL_d78a1adfcddb464292abdaf3104fdad7",
              "IPY_MODEL_708463985d0740fc9ba121ecf69840d8"
            ],
            "layout": "IPY_MODEL_13672eb1c5764104a1936359d66d1e9d"
          }
        },
        "5a63ae8dab834217b154efa90ddf0fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f114bb21297b4f8d91d9a566d5636ac1",
            "placeholder": "​",
            "style": "IPY_MODEL_4f47e1cbcd284a88b09f1167e7c486c6",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "d78a1adfcddb464292abdaf3104fdad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a9def45cc1d4870b7f6d3b2b3fea129",
            "max": 568,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3935615535b4937ac7c090c00317855",
            "value": 568
          }
        },
        "708463985d0740fc9ba121ecf69840d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0ffa3575cc04c7aa15abcbf86a0f7a6",
            "placeholder": "​",
            "style": "IPY_MODEL_05d6978e78da4893a23ecc853d5ad66a",
            "value": " 568/568 [00:00&lt;00:00, 19.9kB/s]"
          }
        },
        "13672eb1c5764104a1936359d66d1e9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f114bb21297b4f8d91d9a566d5636ac1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f47e1cbcd284a88b09f1167e7c486c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a9def45cc1d4870b7f6d3b2b3fea129": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3935615535b4937ac7c090c00317855": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0ffa3575cc04c7aa15abcbf86a0f7a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05d6978e78da4893a23ecc853d5ad66a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNXi6afZ71Yd"
      },
      "outputs": [],
      "source": [
        "#installs\n",
        "!pip install --quiet monai transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F\n",
        "from typing import Any, Optional, Tuple, Type, List, Dict\n",
        "import transformers\n",
        "from transformers import CLIPTextConfig, CLIPTokenizer, CLIPTextModel, AutoTokenizer\n",
        "import monai\n",
        "import numpy as np\n",
        "import math"
      ],
      "metadata": {
        "id": "X6_nSmTN8gpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Image Encoder\n",
        "\n",
        "# Copyright (c) ImageRx and Anish Salvi.\n",
        "# All rights reserved.\n",
        "\n",
        "class LayerNorm3d(nn.Module):\n",
        "    def __init__(self, num_channels: int, eps: float = 1e-6) -> None:\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(num_channels))\n",
        "        self.bias = nn.Parameter(torch.zeros(num_channels))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        u = x.mean(1, keepdim=True)\n",
        "        s = (x - u).pow(2).mean(1, keepdim=True)\n",
        "        x = (x - u) / torch.sqrt(s + self.eps)\n",
        "        x = self.weight[:, None, None, None] * x + self.bias[:, None, None, None]\n",
        "        return x\n",
        "\n",
        "class MLPBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_dim: int,\n",
        "        mlp_dim: int,\n",
        "        act: Type[nn.Module] = nn.GELU,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.lin1 = nn.Linear(embedding_dim, mlp_dim)\n",
        "        self.lin2 = nn.Linear(mlp_dim, embedding_dim)\n",
        "        self.act = act()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.lin2(self.act(self.lin1(x)))\n",
        "\n",
        "\n",
        "# This class and its supporting functions below lightly adapted from the ViTDet backbone available at: https://github.com/facebookresearch/detectron2/blob/main/detectron2/modeling/backbone/vit.py # noqa\n",
        "class ImageEncoderViT(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_size: Tuple[int, int, int] = (64, 64, 64),\n",
        "        patch_size: Tuple[int, int, int] = (16, 16, 16),\n",
        "        in_chans: int = 1,\n",
        "        embed_dim: int = 768, #embed_dim / num_heads = img_size? at least 64, not depth\n",
        "        depth: int = 12,\n",
        "        num_heads: int = 12,\n",
        "        mlp_ratio: float = 4.0,\n",
        "        out_chans: int = 256,\n",
        "        qkv_bias: bool = True,\n",
        "        norm_layer: Type[nn.Module] = nn.LayerNorm,\n",
        "        act_layer: Type[nn.Module] = nn.GELU,\n",
        "        use_abs_pos: bool = True,\n",
        "        use_rel_pos: bool = False,\n",
        "        rel_pos_zero_init: bool = True,\n",
        "        window_size: int = 0,\n",
        "        global_attn_indexes: Tuple[int, ...] = (),\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img_size (int): Input image size.\n",
        "            patch_size (int): Patch size.\n",
        "            in_chans (int): Number of input image channels.\n",
        "            embed_dim (int): Patch embedding dimension.\n",
        "            depth (int): Depth of ViT.\n",
        "            num_heads (int): Number of attention heads in each ViT block.\n",
        "            mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
        "            qkv_bias (bool): If True, add a learnable bias to query, key, value.\n",
        "            norm_layer (nn.Module): Normalization layer.\n",
        "            act_layer (nn.Module): Activation layer.\n",
        "            use_abs_pos (bool): If True, use absolute positional embeddings.\n",
        "            use_rel_pos (bool): If True, add relative positional embeddings to the attention map.\n",
        "            rel_pos_zero_init (bool): If True, zero initialize relative positional parameters.\n",
        "            window_size (int): Window size for window attention blocks.\n",
        "            global_attn_indexes (list): Indexes for blocks using global attention.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        #store\n",
        "        self.img_size = img_size\n",
        "        self.patch_size = patch_size\n",
        "        self.in_chans = in_chans\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.mlp_ratio = mlp_ratio\n",
        "        self.out_chans = out_chans\n",
        "\n",
        "        self.patch_embed = PatchEmbed(\n",
        "            kernel_size = patch_size,\n",
        "            stride = patch_size,\n",
        "            in_chans = in_chans,\n",
        "            embed_dim = embed_dim,\n",
        "        )\n",
        "\n",
        "        self.pos_embed: Optional[nn.Parameter] = None\n",
        "        if use_abs_pos:\n",
        "            # Initialize absolute positional embedding with pretrain image size.\n",
        "            self.pos_embed = nn.Parameter(\n",
        "                torch.zeros(1, img_size[0] // patch_size[0], img_size[1] // patch_size[1], img_size[2] // patch_size[2], embed_dim)\n",
        "            )\n",
        "\n",
        "        self.blocks = nn.ModuleList()\n",
        "        for i in range(depth):\n",
        "            block = Block(\n",
        "                dim=embed_dim,\n",
        "                num_heads=num_heads,\n",
        "                mlp_ratio=mlp_ratio,\n",
        "                qkv_bias=qkv_bias,\n",
        "                norm_layer=norm_layer,\n",
        "                act_layer=act_layer,\n",
        "                use_rel_pos=use_rel_pos,\n",
        "                rel_pos_zero_init=rel_pos_zero_init,\n",
        "                window_size=window_size if i not in global_attn_indexes else 0,\n",
        "                input_size=(img_size[0] // patch_size[0], img_size[1] // patch_size[1], img_size[2] // patch_size[2]),\n",
        "            )\n",
        "            self.blocks.append(block)\n",
        "\n",
        "        self.neck = nn.Sequential(\n",
        "            nn.Conv3d(\n",
        "                embed_dim,\n",
        "                out_chans,\n",
        "                kernel_size=1,\n",
        "                bias=False,\n",
        "            ),\n",
        "            LayerNorm3d(out_chans),\n",
        "            nn.Conv3d(\n",
        "                out_chans,\n",
        "                out_chans,\n",
        "                kernel_size=3,\n",
        "                padding=1,\n",
        "                bias=False,\n",
        "            ),\n",
        "            LayerNorm3d(out_chans),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.patch_embed(x)\n",
        "        if self.pos_embed is not None:\n",
        "            x = x + self.pos_embed\n",
        "\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x)\n",
        "\n",
        "        x = self.neck(x.permute(0, 4, 1, 2, 3))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\"Transformer blocks with support of window attention and residual propagation blocks\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim: int,\n",
        "        num_heads: int,\n",
        "        mlp_ratio: float = 4.0,\n",
        "        qkv_bias: bool = True,\n",
        "        norm_layer: Type[nn.Module] = nn.LayerNorm,\n",
        "        act_layer: Type[nn.Module] = nn.GELU,\n",
        "        use_rel_pos: bool = False,\n",
        "        rel_pos_zero_init: bool = True,\n",
        "        window_size: int = 0,\n",
        "        input_size: Optional[Tuple[int, int, int]] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dim (int): Number of input channels.\n",
        "            num_heads (int): Number of attention heads in each ViT block.\n",
        "            mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.\n",
        "            qkv_bias (bool): If True, add a learnable bias to query, key, value.\n",
        "            norm_layer (nn.Module): Normalization layer.\n",
        "            act_layer (nn.Module): Activation layer.\n",
        "            use_rel_pos (bool): If True, add relative positional embeddings to the attention map.\n",
        "            rel_pos_zero_init (bool): If True, zero initialize relative positional parameters.\n",
        "            window_size (int): Window size for window attention blocks. If it equals 0, then\n",
        "                use global attention.\n",
        "            input_size (tuple(int, int, int) or None): Input resolution for calculating the relative\n",
        "                positional parameter size.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.norm1 = norm_layer(dim)\n",
        "        self.attn = AttentionViT(\n",
        "            dim,\n",
        "            num_heads=num_heads,\n",
        "            qkv_bias=qkv_bias,\n",
        "            use_rel_pos=use_rel_pos,\n",
        "            rel_pos_zero_init=rel_pos_zero_init,\n",
        "            input_size=input_size if window_size == 0 else (window_size, window_size, window_size),\n",
        "        )\n",
        "\n",
        "        self.norm2 = norm_layer(dim)\n",
        "        self.mlp = MLPBlock(embedding_dim=dim, mlp_dim=int(dim * mlp_ratio), act=act_layer)\n",
        "\n",
        "        self.window_size = window_size\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        # Window partition\n",
        "        if self.window_size > 0:\n",
        "            H, W, D = x.shape[1], x.shape[2], x.shape[3]\n",
        "            x, pad_hwd = window_partition(x, self.window_size)\n",
        "\n",
        "        x = self.attn(x)\n",
        "        # Reverse window partition\n",
        "        if self.window_size > 0:\n",
        "            x = window_unpartition(x, self.window_size, pad_hwd, (H, W, D))\n",
        "\n",
        "        x = shortcut + x\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class AttentionViT(nn.Module):\n",
        "    \"\"\"Multi-head Attention block with relative position embeddings.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim: int,\n",
        "        num_heads: int = 8,\n",
        "        qkv_bias: bool = True,\n",
        "        use_rel_pos: bool = False,\n",
        "        rel_pos_zero_init: bool = True,\n",
        "        input_size: Optional[Tuple[int, int, int]] = None,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dim (int): Number of input channels.\n",
        "            num_heads (int): Number of attention heads.\n",
        "            qkv_bias (bool):  If True, add a learnable bias to query, key, value.\n",
        "            rel_pos (bool): If True, add relative positional embeddings to the attention map.\n",
        "            rel_pos_zero_init (bool): If True, zero initialize relative positional parameters.\n",
        "            input_size (tuple(int, int) or None): Input resolution for calculating the relative\n",
        "                positional parameter size.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim**-0.5\n",
        "\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "\n",
        "        self.use_rel_pos = use_rel_pos\n",
        "        if self.use_rel_pos:\n",
        "            assert (\n",
        "                input_size is not None\n",
        "            ), \"Input size must be provided if using relative positional encoding.\"\n",
        "            # initialize relative positional embeddings\n",
        "            self.rel_pos_h = nn.Parameter(torch.zeros(2 * input_size[0] - 1, head_dim))\n",
        "            self.rel_pos_w = nn.Parameter(torch.zeros(2 * input_size[1] - 1, head_dim))\n",
        "            self.rel_pos_d = nn.Parameter(torch.zeros(2 * input_size[2] - 1, head_dim))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        B, H, W, D, _ = x.shape\n",
        "        # qkv with shape (3, B, nHead, H * W * D, C)\n",
        "        qkv = self.qkv(x).reshape(B, H * W * D, 3, self.num_heads, -1).permute(2, 0, 3, 1, 4)\n",
        "        # q, k, v with shape (B * nHead, H * W * D, C)\n",
        "        q, k, v = qkv.reshape(3, B * self.num_heads, H * W * D, -1).unbind(0)\n",
        "\n",
        "        attn = (q * self.scale) @ k.transpose(-2, -1)\n",
        "\n",
        "        if self.use_rel_pos:\n",
        "            attn = add_decomposed_rel_pos(attn, q, self.rel_pos_h, self.rel_pos_w, self.rel_pos_d, (H, W, D), (H, W, D))\n",
        "\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        x = (attn @ v).view(B, self.num_heads, H, W, D, -1).permute(0, 2, 3, 4, 1, 5).reshape(B, H, W, D, -1)\n",
        "        x = self.proj(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def window_partition(x: torch.Tensor, window_size: int) -> Tuple[torch.Tensor, Tuple[int, int, int]]:\n",
        "    \"\"\"\n",
        "    Partition into non-overlapping windows with padding if needed.\n",
        "    Args:\n",
        "        x (tensor): input tokens with [B, C, H, W, D].\n",
        "        window_size (int): window size.\n",
        "\n",
        "    Returns:\n",
        "        windows: windows after partition with [B * num_windows, window_size, window_size, window_size, C].\n",
        "        (Hp, Wp, Dp): padded height and width before partition\n",
        "    \"\"\"\n",
        "    B, C, H, W, D = x.shape\n",
        "\n",
        "    pad_h = (window_size - H % window_size) % window_size\n",
        "    pad_w = (window_size - W % window_size) % window_size\n",
        "    pad_d = (window_size - D % window_size) % window_size\n",
        "    if pad_h > 0 or pad_w > 0 or pad_d > 0:\n",
        "        x = F.pad(x, (0, 0, 0, pad_w, 0, pad_h, 0, pad_d))\n",
        "    Hp, Wp, Dp = H + pad_h, W + pad_w, D + pad_d\n",
        "\n",
        "    x = x.view(B, Hp // window_size, window_size, Wp // window_size, window_size, Dp // window_size, window_size, C)\n",
        "    windows = x.contiguous().view(-1, window_size, window_size, window_size, C) #permute removed\n",
        "    return windows, (Hp, Wp, Dp)\n",
        "\n",
        "\n",
        "def window_unpartition(\n",
        "    windows: torch.Tensor, window_size: int, pad_hwd: Tuple[int, int, int], hwd: Tuple[int, int, int]\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Window unpartition into original sequences and removing padding.\n",
        "    Args:\n",
        "        windows (tensor): input tokens with [B * num_windows, window_size, window_size, window_size, C].\n",
        "        window_size (int): window size.\n",
        "        pad_hwd (Tuple): padded height and width (Hp, Wp, Dp).\n",
        "        hwd (Tuple): original height and width (H, W, D) before padding.\n",
        "\n",
        "    Returns:\n",
        "        x: unpartitioned sequences with [B, C, H, W, D].\n",
        "    \"\"\"\n",
        "    Hp, Wp, Dp = pad_hwd\n",
        "    H, W, D = hwd\n",
        "    B = windows.shape[0] // (Hp * Wp * Dp // window_size // window_size // window_size)\n",
        "    x = windows.view(B, Hp // window_size, Wp // window_size, Dp // window_size, window_size, window_size, window_size, -1)\n",
        "    x = x.contiguous().view(B, Hp, Wp, Dp, -1) #permute removed\n",
        "\n",
        "    if Hp > H or Wp > W or Dp > D:\n",
        "        x = x[:, :H, :W, :D, :].contiguous()\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_rel_pos(q_size: int, k_size: int, rel_pos: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Get relative positional embeddings according to the relative positions of\n",
        "        query and key sizes.\n",
        "    Args:\n",
        "        q_size (int): size of query q.\n",
        "        k_size (int): size of key k.\n",
        "        rel_pos (Tensor): relative position embeddings (L, C).\n",
        "\n",
        "    Returns:\n",
        "        Extracted positional embeddings according to relative positions.\n",
        "    \"\"\"\n",
        "    max_rel_dist = int(2 * max(q_size, k_size) - 1)\n",
        "    # Interpolate rel pos if needed.\n",
        "    if rel_pos.shape[0] != max_rel_dist:\n",
        "        # Interpolate rel pos.\n",
        "        rel_pos_resized = F.interpolate(\n",
        "            rel_pos.reshape(1, rel_pos.shape[0], -1).permute(0, 2, 1),\n",
        "            size=max_rel_dist,\n",
        "            mode=\"linear\",\n",
        "        )\n",
        "        rel_pos_resized = rel_pos_resized.reshape(-1, max_rel_dist).permute(1, 0)\n",
        "    else:\n",
        "        rel_pos_resized = rel_pos\n",
        "\n",
        "    # Scale the coords with short length if shapes for q and k are different.\n",
        "    q_coords = torch.arange(q_size)[:, None] * max(k_size / q_size, 1.0)\n",
        "    k_coords = torch.arange(k_size)[None, :] * max(q_size / k_size, 1.0)\n",
        "    relative_coords = (q_coords - k_coords) + (k_size - 1) * max(q_size / k_size, 1.0)\n",
        "\n",
        "    return rel_pos_resized[relative_coords.long()]\n",
        "\n",
        "\n",
        "def add_decomposed_rel_pos(\n",
        "    attn: torch.Tensor,\n",
        "    q: torch.Tensor,\n",
        "    rel_pos_h: torch.Tensor,\n",
        "    rel_pos_w: torch.Tensor,\n",
        "    rel_pos_d: torch.Tensor,\n",
        "    q_size: Tuple[int, int, int],\n",
        "    k_size: Tuple[int, int, int],\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Calculate decomposed Relative Positional Embeddings from :paper:`mvitv2`.\n",
        "    https://github.com/facebookresearch/mvit/blob/19786631e330df9f3622e5402b4a419a263a2c80/mvit/models/attention.py   # noqa B950\n",
        "    Args:\n",
        "        attn (Tensor): attention map.\n",
        "        q (Tensor): query q in the attention layer with shape (B, q_h * q_w * q_d, C).\n",
        "        rel_pos_h (Tensor): relative position embeddings (Lh, C) for height axis.\n",
        "        rel_pos_w (Tensor): relative position embeddings (Lw, C) for width axis.\n",
        "        rel_pos_d (Tensor): relative position embeddings (Ld, C) for depth axis.\n",
        "        q_size (Tuple): spatial sequence size of query q with (q_h, q_w, q_d).\n",
        "        k_size (Tuple): spatial sequence size of key k with (k_h, k_w, k_d).\n",
        "\n",
        "    Returns:\n",
        "        attn (Tensor): attention map with added relative positional embeddings.\n",
        "    \"\"\"\n",
        "    q_h, q_w, q_d = q_size\n",
        "    k_h, k_w, k_d = k_size\n",
        "\n",
        "    Rh = get_rel_pos(q_h, k_h, rel_pos_h)\n",
        "    Rw = get_rel_pos(q_w, k_w, rel_pos_w)\n",
        "    Rd = get_rel_pos(q_d, k_d, rel_pos_d)\n",
        "\n",
        "    B, _, dim = q.shape\n",
        "    r_q = q.reshape(B, q_h, q_w, q_d, dim)\n",
        "    rel_h = torch.einsum(\"bhwdc,hkc->bhwdk\", r_q, Rh)\n",
        "    rel_w = torch.einsum(\"bhwdc,wkc->bhwdk\", r_q, Rw)\n",
        "    rel_d = torch.einsum(\"bhwdc,dkc->bhwdk\", r_q, Rd)\n",
        "\n",
        "    attn = (\n",
        "        attn.view(B, q_h, q_w, q_d, k_h, k_w, k_d)\n",
        "        + rel_h[:, :, :, :, :, None] + rel_w[:, :, :, :, None, :] + rel_d[:, :, :, None, :, :]\n",
        "        ).view(B, q_h * q_w * q_d, k_h * k_w * k_d)\n",
        "\n",
        "    return attn\n",
        "\n",
        "class PatchEmbed(nn.Module):\n",
        "    \"\"\"\n",
        "    Image to Patch Embedding.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        kernel_size: Tuple[int, int, int] = (16, 16, 16),\n",
        "        stride: Tuple[int, int, int] = (16, 16, 16),\n",
        "        padding: Tuple[int, int, int] = (0, 0, 0),\n",
        "        in_chans: int = 1,\n",
        "        embed_dim: int = 768,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            kernel_size (Tuple): kernel size of the projection layer.\n",
        "            stride (Tuple): stride of the projection layer.\n",
        "            padding (Tuple): padding size of the projection layer.\n",
        "            in_chans (int): Number of input image channels.\n",
        "            embed_dim (int): Patch embedding dimension.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.proj = nn.Conv3d(\n",
        "            in_chans, embed_dim, kernel_size=kernel_size, stride=stride, padding=padding\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.proj(x)\n",
        "        # B C H W D -> B H W D C\n",
        "        x = x.permute(0, 2, 3, 4, 1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "RHM2rkwd9Tog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prompt Encoder\n",
        "\n",
        "# Copyright (c) ImageRx and Anish Salvi.\n",
        "# All rights reserved.\n",
        "\n",
        "def divide(test_tup1, test_tup2):\n",
        "  return tuple(ele1 // ele2 for ele1, ele2 in zip(test_tup1, test_tup2))\n",
        "\n",
        "def get_down_scaling(kernel_stride_size, mask_in_chans, embed_dim):\n",
        "      max_downscaling = nn.Sequential()\n",
        "      #iterate\n",
        "      for i in range(len(kernel_stride_size)):\n",
        "        max_downscaling.add_module(\"conv_\" + str(i), nn.Conv3d(mask_in_chans[i], mask_in_chans[i + 1],\n",
        "                                                           kernel_size = kernel_stride_size[i], stride = kernel_stride_size[i]))\n",
        "        max_downscaling.add_module(\"norm_\" + str(i), LayerNorm3d(mask_in_chans[i + 1]))\n",
        "        max_downscaling.add_module(\"act_\" + str(i), torch.nn.GELU())\n",
        "      max_downscaling.add_module(\"embed_\" + str(0), torch.nn.Conv3d(mask_in_chans[i + 1], embed_dim, kernel_size=1))\n",
        "      #return\n",
        "      return max_downscaling\n",
        "\n",
        "\n",
        "class PromptEncoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embed_dim: int,\n",
        "        input_image_size: Tuple[int, int, int],\n",
        "        patch_size: Tuple[int, int, int],\n",
        "        mask_in_chans: List,\n",
        "        kernel_stride_size: List,\n",
        "        num_attention_heads: int,\n",
        "        num_hidden_layers: int,\n",
        "        projection_dim: int,\n",
        "        intermediate_size: int,\n",
        "        max_position_embeddings: int,\n",
        "        activation: Type[nn.Module] = nn.GELU,\n",
        "        tokenizer: Optional[AutoTokenizer] = None\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Encodes prompts for input to SAM's mask decoder.\n",
        "\n",
        "        Arguments:\n",
        "          embed_dim (int): The prompts' embedding dimension\n",
        "          input_image_size (int): The padded size of the image as input\n",
        "            to the image encoder, as (H, W, D).\n",
        "          patch_size (tuple(int, int, int)): The spatial size of the\n",
        "            image embedding, as (H, W, D).\n",
        "          mask_in_chans (int): The number of hidden channels used for\n",
        "            encoding input masks.\n",
        "          activation (nn.Module): The activation to use when encoding\n",
        "            input masks.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.input_image_size = input_image_size\n",
        "        self.pe_layer = PositionEmbeddingRandom(embed_dim // 2)\n",
        "\n",
        "        self.num_point_embeddings: int = 4  # pos/neg point + 2 box corners\n",
        "        point_embeddings = [nn.Embedding(1, embed_dim) for i in range(self.num_point_embeddings)]\n",
        "        self.point_embeddings = nn.ModuleList(point_embeddings)\n",
        "        self.not_a_point_embed = nn.Embedding(1, embed_dim)\n",
        "        self.image_embedding_size = divide(self.input_image_size, patch_size)\n",
        "\n",
        "        #might need deeper network?\n",
        "        self.mask_downscaling = get_down_scaling(kernel_stride_size, mask_in_chans, embed_dim)\n",
        "        self.no_mask_embed = nn.Embedding(1, embed_dim)\n",
        "\n",
        "        #init\n",
        "        path = \"openai/clip-vit-base-patch32\"\n",
        "        #get config\n",
        "        config = CLIPTextConfig.from_pretrained(path)\n",
        "        #if\n",
        "        if tokenizer is None:\n",
        "          #get tokenizer\n",
        "          self.tokenizer = CLIPTokenizer.from_pretrained(path)\n",
        "          #set\n",
        "          config.bos_token_id = self.tokenizer.bos_token_id\n",
        "          config.eos_token_id = self.tokenizer.eos_token_id\n",
        "        else:\n",
        "          #get tokenizer\n",
        "          self.tokenizer = tokenizer\n",
        "          #set\n",
        "          config.bos_token_id = self.tokenizer.bos_token_id\n",
        "          config.eos_token_id = self.tokenizer.eos_token_id\n",
        "        #set\n",
        "        config.num_attention_heads = num_attention_heads\n",
        "        config.num_hidden_layers = num_hidden_layers\n",
        "        config.projection_dim = projection_dim\n",
        "        config.intermediate_size = intermediate_size\n",
        "        config.max_position_embeddings = max_position_embeddings\n",
        "        #set hidden state\n",
        "        config.hidden_size = embed_dim\n",
        "        #model\n",
        "        self.text_model = CLIPTextModel(config)\n",
        "\n",
        "    def get_dense_pe(self) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Returns the positional encoding used to encode point prompts,\n",
        "        applied to a dense set of points the shape of the image encoding.\n",
        "\n",
        "        Returns:\n",
        "          torch.Tensor: Positional encoding with shape\n",
        "            1x(embed_dim)x(embedding_h)x(embedding_w)x(embedding_d)\n",
        "        \"\"\"\n",
        "        return self.pe_layer(self.image_embedding_size).unsqueeze(0)\n",
        "\n",
        "    def _embed_points(\n",
        "        self,\n",
        "        points: torch.Tensor,\n",
        "        labels: torch.Tensor,\n",
        "        pad: bool,\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"Embeds point prompts.\"\"\"\n",
        "        points = points + 0.5  # Shift to center of pixel\n",
        "        if pad:\n",
        "            padding_point = torch.zeros((points.shape[0], 1, 3), device=points.device)\n",
        "            padding_label = -torch.ones((labels.shape[0], 1), device=labels.device)\n",
        "            points = torch.cat([points, padding_point], dim=1)\n",
        "            labels = torch.cat([labels, padding_label], dim=1)\n",
        "        point_embedding = self.pe_layer.forward_with_coords(points, self.input_image_size)\n",
        "        point_embedding[labels == -1] = 0.0\n",
        "        point_embedding[labels == -1] += self.not_a_point_embed.weight\n",
        "        point_embedding[labels == 0] += self.point_embeddings[0].weight\n",
        "        point_embedding[labels == 1] += self.point_embeddings[1].weight\n",
        "        return point_embedding\n",
        "\n",
        "    def _embed_boxes(self, boxes: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Embeds box prompts.\"\"\"\n",
        "        boxes = boxes + 0.5  # Shift to center of pixel\n",
        "        coords = boxes.reshape(-1, 2, 3)\n",
        "        corner_embedding = self.pe_layer.forward_with_coords(coords, self.input_image_size)\n",
        "        corner_embedding[:, 0, :] += self.point_embeddings[2].weight\n",
        "        corner_embedding[:, 1, :] += self.point_embeddings[3].weight\n",
        "        return corner_embedding\n",
        "\n",
        "    def _embed_masks(self, masks: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Embeds mask inputs.\"\"\"\n",
        "        mask_embedding = self.mask_downscaling(masks)\n",
        "        return mask_embedding\n",
        "\n",
        "    def _embed_text(self, text):\n",
        "        \"\"\"Embeds text inputs.\"\"\"\n",
        "        inputs = self.tokenizer(text, padding=True, return_tensors=\"pt\").to(self._get_device())\n",
        "        outputs = self.text_model(**inputs)\n",
        "        return outputs.pooler_output[:, None, :]\n",
        "\n",
        "    def _get_batch_size(\n",
        "        self,\n",
        "        points: Optional[Tuple[torch.Tensor, torch.Tensor]],\n",
        "        boxes: Optional[torch.Tensor],\n",
        "        masks: Optional[torch.Tensor],\n",
        "        text: Optional[List]\n",
        "    ) -> int:\n",
        "        \"\"\"\n",
        "        Gets the batch size of the output given the batch size of the input prompts.\n",
        "        \"\"\"\n",
        "        if points[0] is not None:\n",
        "          return points[0].shape[0]\n",
        "        elif boxes is not None:\n",
        "          return boxes.shape[0]\n",
        "        elif text is not None:\n",
        "          return len(text)\n",
        "        elif masks is not None:\n",
        "          return masks.shape[0]\n",
        "        else:\n",
        "          return 1\n",
        "\n",
        "    def _get_device(self) -> torch.device:\n",
        "        return self.point_embeddings[0].weight.device\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        points: Optional[Tuple[torch.Tensor, torch.Tensor]],\n",
        "        boxes: Optional[torch.Tensor],\n",
        "        masks: Optional[torch.Tensor],\n",
        "        text: Optional[List],\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Embeds different types of prompts, returning both sparse and dense\n",
        "        embeddings.\n",
        "\n",
        "        Arguments:\n",
        "          points (tuple(torch.Tensor, torch.Tensor) or none): point coordinates\n",
        "            and labels to embed.\n",
        "          boxes (torch.Tensor or none): boxes to embed\n",
        "          masks (torch.Tensor or none): masks to embed\n",
        "          text  (list): text to embed\n",
        "\n",
        "        Returns:\n",
        "          torch.Tensor: sparse embeddings for the points and boxes, with shape\n",
        "            BxNx(embed_dim), where N is determined by the number of input points\n",
        "            and boxes.\n",
        "          torch.Tensor: dense embeddings for the masks, in the shape\n",
        "            Bx(embed_dim)x(embed_H)x(embed_W)x(embed_D)\n",
        "        \"\"\"\n",
        "        bs = self._get_batch_size(points, boxes, masks, text)\n",
        "        sparse_embeddings = torch.empty((bs, 0, self.embed_dim), device=self._get_device())\n",
        "        if points[0] is not None:\n",
        "            coords, labels = points\n",
        "            point_embeddings = self._embed_points(coords, labels, pad=(boxes is None))\n",
        "            sparse_embeddings = torch.cat([sparse_embeddings, point_embeddings], dim=1)\n",
        "        if boxes is not None:\n",
        "            box_embeddings = self._embed_boxes(boxes)\n",
        "            sparse_embeddings = torch.cat([sparse_embeddings, box_embeddings], dim=1)\n",
        "        if text is not None:\n",
        "            text_embeddings = self._embed_text(text)\n",
        "            sparse_embeddings = torch.cat([sparse_embeddings, text_embeddings], dim=1)\n",
        "        if masks is not None:\n",
        "            dense_embeddings = self._embed_masks(masks)\n",
        "        else:\n",
        "            dense_embeddings = self.no_mask_embed.weight.reshape(1, -1, 1, 1, 1).expand(\n",
        "                bs, -1, self.image_embedding_size[0], self.image_embedding_size[1], self.image_embedding_size[2]\n",
        "                )\n",
        "\n",
        "        return sparse_embeddings, dense_embeddings\n",
        "\n",
        "\n",
        "class PositionEmbeddingRandom(nn.Module):\n",
        "    \"\"\"\n",
        "    Positional encoding using random spatial frequencies.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_pos_feats: int = 64, scale: Optional[float] = None) -> None:\n",
        "        super().__init__()\n",
        "        if scale is None or scale <= 0.0:\n",
        "            scale = 1.0\n",
        "        self.register_buffer(\n",
        "            \"positional_encoding_gaussian_matrix\",\n",
        "            scale * torch.randn((3, num_pos_feats)),\n",
        "        )\n",
        "\n",
        "    def _pe_encoding(self, coords: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Positionally encode points that are normalized to [0,1].\"\"\"\n",
        "        # assuming coords are in [0, 1]^2 square and have d_1 x ... x d_n x 2 shape\n",
        "        coords = 2 * coords - 1\n",
        "        coords = coords @ self.positional_encoding_gaussian_matrix\n",
        "        coords = 2 * np.pi * coords\n",
        "        # outputs d_1 x ... x d_n x C shape\n",
        "        return torch.cat([torch.sin(coords), torch.cos(coords)], dim=-1)\n",
        "\n",
        "    def forward(self, size: Tuple[int, int, int]) -> torch.Tensor:\n",
        "        \"\"\"Generate positional encoding for a grid of the specified size.\"\"\"\n",
        "        h, w, d = size\n",
        "        device: Any = self.positional_encoding_gaussian_matrix.device\n",
        "        grid = torch.ones((h, w, d), device=device, dtype=torch.float32)\n",
        "        #embed\n",
        "        x_embed = grid.cumsum(dim=0) - 0.5\n",
        "        y_embed = grid.cumsum(dim=1) - 0.5\n",
        "        z_embed = grid.cumsum(dim=2) - 0.5\n",
        "        #norm\n",
        "        x_embed = x_embed / h\n",
        "        y_embed = y_embed / w\n",
        "        z_embed = z_embed / d\n",
        "        #encode\n",
        "        pe = self._pe_encoding(torch.stack([x_embed, y_embed, z_embed], dim=-1))\n",
        "        return pe.permute(3, 0, 1, 2)  # C x H x W x D\n",
        "\n",
        "    def forward_with_coords(\n",
        "        self, coords_input: torch.Tensor, image_size: Tuple[int, int, int]\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"Positionally encode points that are not normalized to [0,1].\"\"\"\n",
        "        coords = coords_input.clone()\n",
        "        coords[:, :, 0] = coords[:, :, 0] / image_size[0]\n",
        "        coords[:, :, 1] = coords[:, :, 1] / image_size[1]\n",
        "        coords[:, :, 2] = coords[:, :, 2] / image_size[2]\n",
        "        return self._pe_encoding(coords.to(torch.float))  # B x N x C"
      ],
      "metadata": {
        "id": "IlIVEmEY9Wbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Transformer\n",
        "\n",
        "# Copyright (c) ImageRx and Anish Salvi.\n",
        "# All rights reserved.\n",
        "\n",
        "class TwoWayTransformerMLPBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_dim: int,\n",
        "        mlp_dim: int,\n",
        "        act: Type[nn.Module] = nn.GELU,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.lin1 = nn.Linear(embedding_dim, mlp_dim)\n",
        "        self.lin2 = nn.Linear(mlp_dim, embedding_dim)\n",
        "        self.act = act()\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.lin2(self.act(self.lin1(x)))\n",
        "\n",
        "\n",
        "class TwoWayTransformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        depth: int,\n",
        "        embedding_dim: int,\n",
        "        num_heads: int,\n",
        "        mlp_dim: int,\n",
        "        activation: Type[nn.Module] = nn.ReLU,\n",
        "        attention_downsample_rate: int = 2,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        A transformer decoder that attends to an input image using\n",
        "        queries whose positional embedding is supplied.\n",
        "\n",
        "        Args:\n",
        "          depth (int): number of layers in the transformer\n",
        "          embedding_dim (int): the channel dimension for the input embeddings\n",
        "          num_heads (int): the number of heads for multihead attention. Must\n",
        "            divide embedding_dim\n",
        "          mlp_dim (int): the channel dimension internal to the MLP block\n",
        "          activation (nn.Module): the activation to use in the MLP block\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.depth = depth\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.mlp_dim = mlp_dim\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        for i in range(depth):\n",
        "            self.layers.append(\n",
        "                TwoWayAttentionBlock(\n",
        "                    embedding_dim=embedding_dim,\n",
        "                    num_heads=num_heads,\n",
        "                    mlp_dim=mlp_dim,\n",
        "                    activation=activation,\n",
        "                    attention_downsample_rate=attention_downsample_rate,\n",
        "                    skip_first_layer_pe=(i == 0),\n",
        "                )\n",
        "            )\n",
        "\n",
        "        self.final_attn_token_to_image = TwoWayTransformerAttention(\n",
        "            embedding_dim, num_heads, downsample_rate=attention_downsample_rate\n",
        "        )\n",
        "        self.norm_final_attn = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        image_embedding: Tensor,\n",
        "        image_pe: Tensor,\n",
        "        point_embedding: Tensor,\n",
        "    ) -> Tuple[Tensor, Tensor]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          image_embedding (torch.Tensor): image to attend to. Should be shape\n",
        "            B x embedding_dim x h x w x d for any h and w and d.\n",
        "          image_pe (torch.Tensor): the positional encoding to add to the image. Must\n",
        "            have the same shape as image_embedding.\n",
        "          point_embedding (torch.Tensor): the embedding to add to the query points.\n",
        "            Must have shape B x N_points x embedding_dim for any N_points.\n",
        "\n",
        "        Returns:\n",
        "          torch.Tensor: the processed point_embedding\n",
        "          torch.Tensor: the processed image_embedding\n",
        "        \"\"\"\n",
        "        # BxCxHxW -> BxHWxC == B x N_image_tokens x C\n",
        "        #bs, c, h, w, d = image_embedding.shape\n",
        "        image_embedding = image_embedding.flatten(2).permute(0, 2, 1)\n",
        "        image_pe = image_pe.flatten(2).permute(0, 2, 1)\n",
        "\n",
        "        # Prepare queries\n",
        "        queries = point_embedding\n",
        "        keys = image_embedding\n",
        "\n",
        "        # Apply transformer blocks and final layernorm\n",
        "        for layer in self.layers:\n",
        "            queries, keys = layer(\n",
        "                queries=queries,\n",
        "                keys=keys,\n",
        "                query_pe=point_embedding,\n",
        "                key_pe=image_pe,\n",
        "            )\n",
        "\n",
        "        # Apply the final attention layer from the points to the image\n",
        "        q = queries + point_embedding\n",
        "        k = keys + image_pe\n",
        "        attn_out = self.final_attn_token_to_image(q=q, k=k, v=keys)\n",
        "        queries = queries + attn_out\n",
        "        queries = self.norm_final_attn(queries)\n",
        "\n",
        "        return queries, keys\n",
        "\n",
        "\n",
        "class TwoWayAttentionBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_dim: int,\n",
        "        num_heads: int,\n",
        "        mlp_dim: int = 2048,\n",
        "        activation: Type[nn.Module] = nn.ReLU,\n",
        "        attention_downsample_rate: int = 2,\n",
        "        skip_first_layer_pe: bool = False,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        A transformer block with four layers: (1) self-attention of sparse\n",
        "        inputs, (2) cross attention of sparse inputs to dense inputs, (3) mlp\n",
        "        block on sparse inputs, and (4) cross attention of dense inputs to sparse\n",
        "        inputs.\n",
        "\n",
        "        Arguments:\n",
        "          embedding_dim (int): the channel dimension of the embeddings\n",
        "          num_heads (int): the number of heads in the attention layers\n",
        "          mlp_dim (int): the hidden dimension of the mlp block\n",
        "          activation (nn.Module): the activation of the mlp block\n",
        "          skip_first_layer_pe (bool): skip the PE on the first layer\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.self_attn = TwoWayTransformerAttention(embedding_dim, num_heads)\n",
        "        self.norm1 = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "        self.cross_attn_token_to_image = TwoWayTransformerAttention(\n",
        "            embedding_dim, num_heads, downsample_rate=attention_downsample_rate\n",
        "        )\n",
        "        self.norm2 = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "        self.mlp = TwoWayTransformerMLPBlock(embedding_dim, mlp_dim, activation)\n",
        "        self.norm3 = nn.LayerNorm(embedding_dim)\n",
        "\n",
        "        self.norm4 = nn.LayerNorm(embedding_dim)\n",
        "        self.cross_attn_image_to_token = TwoWayTransformerAttention(\n",
        "            embedding_dim, num_heads, downsample_rate=attention_downsample_rate\n",
        "        )\n",
        "\n",
        "        self.skip_first_layer_pe = skip_first_layer_pe\n",
        "\n",
        "    def forward(\n",
        "        self, queries: Tensor, keys: Tensor, query_pe: Tensor, key_pe: Tensor\n",
        "    ) -> Tuple[Tensor, Tensor]:\n",
        "        # Self attention block\n",
        "        if self.skip_first_layer_pe:\n",
        "            queries = self.self_attn(q=queries, k=queries, v=queries)\n",
        "        else:\n",
        "            q = queries + query_pe\n",
        "            attn_out = self.self_attn(q=q, k=q, v=queries)\n",
        "            queries = queries + attn_out\n",
        "        queries = self.norm1(queries)\n",
        "\n",
        "        # Cross attention block, tokens attending to image embedding\n",
        "        q = queries + query_pe\n",
        "        k = keys + key_pe\n",
        "        attn_out = self.cross_attn_token_to_image(q=q, k=k, v=keys)\n",
        "        queries = queries + attn_out\n",
        "        queries = self.norm2(queries)\n",
        "\n",
        "        # MLP block\n",
        "        mlp_out = self.mlp(queries)\n",
        "        queries = queries + mlp_out\n",
        "        queries = self.norm3(queries)\n",
        "\n",
        "        # Cross attention block, image embedding attending to tokens\n",
        "        q = queries + query_pe\n",
        "        k = keys + key_pe\n",
        "        attn_out = self.cross_attn_image_to_token(q=k, k=q, v=queries)\n",
        "        keys = keys + attn_out\n",
        "        keys = self.norm4(keys)\n",
        "\n",
        "        return queries, keys\n",
        "\n",
        "\n",
        "class TwoWayTransformerAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    An attention layer that allows for downscaling the size of the embedding\n",
        "    after projection to queries, keys, and values.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_dim: int,\n",
        "        num_heads: int,\n",
        "        downsample_rate: int = 1,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.internal_dim = embedding_dim // downsample_rate\n",
        "        self.num_heads = num_heads\n",
        "        assert self.internal_dim % num_heads == 0, \"num_heads must divide embedding_dim.\"\n",
        "\n",
        "        self.q_proj = nn.Linear(embedding_dim, self.internal_dim)\n",
        "        self.k_proj = nn.Linear(embedding_dim, self.internal_dim)\n",
        "        self.v_proj = nn.Linear(embedding_dim, self.internal_dim)\n",
        "        self.out_proj = nn.Linear(self.internal_dim, embedding_dim)\n",
        "\n",
        "    def _separate_heads(self, x: Tensor, num_heads: int) -> Tensor:\n",
        "        b, n, c = x.shape\n",
        "        x = x.reshape(b, n, num_heads, c // num_heads)\n",
        "        return x.transpose(1, 2)  # B x N_heads x N_tokens x C_per_head\n",
        "\n",
        "    def _recombine_heads(self, x: Tensor) -> Tensor:\n",
        "        b, n_heads, n_tokens, c_per_head = x.shape\n",
        "        x = x.transpose(1, 2)\n",
        "        return x.reshape(b, n_tokens, n_heads * c_per_head)  # B x N_tokens x C\n",
        "\n",
        "    def forward(self, q: Tensor, k: Tensor, v: Tensor) -> Tensor:\n",
        "        # Input projections\n",
        "        q = self.q_proj(q)\n",
        "        k = self.k_proj(k)\n",
        "        v = self.v_proj(v)\n",
        "\n",
        "        # Separate into heads\n",
        "        q = self._separate_heads(q, self.num_heads)\n",
        "        k = self._separate_heads(k, self.num_heads)\n",
        "        v = self._separate_heads(v, self.num_heads)\n",
        "\n",
        "        # Attention\n",
        "        _, _, _, c_per_head = q.shape\n",
        "        attn = q @ k.permute(0, 1, 3, 2)  # B x N_heads x N_tokens x N_tokens\n",
        "        attn = attn / math.sqrt(c_per_head)\n",
        "        attn = torch.softmax(attn, dim=-1)\n",
        "\n",
        "        # Get output\n",
        "        out = attn @ v\n",
        "        out = self._recombine_heads(out)\n",
        "        out = self.out_proj(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "kbMPZR2s9bim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mask Decoder\n",
        "\n",
        "# Copyright (c) ImageRx and Anish Salvi.\n",
        "# All rights reserved.\n",
        "\n",
        "def get_output_scaling(kernel_stride_size, transformer_dim):\n",
        "      output_upscaling = nn.Sequential()\n",
        "      #iterate\n",
        "      for i in range(len(kernel_stride_size)):\n",
        "        output_upscaling.add_module(\"conv_\" + str(i), nn.ConvTranspose3d(transformer_dim[i], transformer_dim[i+1],\n",
        "                                                                         kernel_size = kernel_stride_size[i], stride = kernel_stride_size[i]))\n",
        "        if len(kernel_stride_size) - 1 == i:\n",
        "          output_upscaling.add_module(\"act_\" + str(i), torch.nn.GELU())\n",
        "          continue\n",
        "        else:\n",
        "          output_upscaling.add_module(\"norm_\" + str(i), LayerNorm3d(transformer_dim[i + 1]))\n",
        "          output_upscaling.add_module(\"act_\" + str(i), torch.nn.GELU())\n",
        "      #return\n",
        "      return output_upscaling\n",
        "\n",
        "def get_MLP(start_dim, end_dim, num_mask_tokens, num_layers):\n",
        "  output_hypernetworks_mlps = nn.ModuleList([\n",
        "      MLP(start_dim, start_dim, end_dim, num_layers)\n",
        "      for i in range(num_mask_tokens)\n",
        "      ])\n",
        "  return output_hypernetworks_mlps\n",
        "\n",
        "\n",
        "class MaskDecoder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        kernel_stride_size: List,\n",
        "        transformer_dim: List,\n",
        "        patch_size: Tuple[int, int, int],\n",
        "        transformer: nn.Module,\n",
        "        num_multimask_outputs: int = 3,\n",
        "        activation: Type[nn.Module] = nn.GELU,\n",
        "        iou_head_depth: int = 3,\n",
        "        iou_head_hidden_dim: int = 256,\n",
        "        num_layers: int = 3\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Predicts masks given an image and prompt embeddings, using a\n",
        "        transformer architecture.\n",
        "\n",
        "        Arguments:\n",
        "          transformer_dim (int): the channel dimension of the transformer\n",
        "          patch_size Tuple(int, int, int): the patch size used in the encoder\n",
        "          transformer (nn.Module): the transformer used to predict masks\n",
        "          num_multimask_outputs (int): the number of masks to predict\n",
        "            when disambiguating masks\n",
        "          activation (nn.Module): the type of activation to use when\n",
        "            upscaling masks\n",
        "          iou_head_depth (int): the depth of the MLP used to predict\n",
        "            mask quality\n",
        "          iou_head_hidden_dim (int): the hidden dimension of the MLP\n",
        "            used to predict mask quality\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.transformer = transformer\n",
        "        self.num_multimask_outputs = num_multimask_outputs\n",
        "\n",
        "        self.iou_token = nn.Embedding(1, transformer_dim[0])\n",
        "        self.num_mask_tokens = num_multimask_outputs + 1\n",
        "        self.mask_tokens = nn.Embedding(self.num_mask_tokens, transformer_dim[0])\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "        self.output_upscaling = get_output_scaling(kernel_stride_size, transformer_dim)\n",
        "        self.output_hypernetworks_mlps = get_MLP(transformer_dim[0], transformer_dim[-1], self.num_mask_tokens, num_layers)\n",
        "\n",
        "        self.iou_prediction_head = MLP(\n",
        "            transformer_dim[0], iou_head_hidden_dim, self.num_mask_tokens, iou_head_depth\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        image_embeddings: torch.Tensor,\n",
        "        image_pe: torch.Tensor,\n",
        "        sparse_prompt_embeddings: torch.Tensor,\n",
        "        dense_prompt_embeddings: torch.Tensor,\n",
        "        multimask_output: bool,\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Predict masks given image and prompt embeddings.\n",
        "\n",
        "        Arguments:\n",
        "          image_embeddings (torch.Tensor): the embeddings from the image encoder\n",
        "          image_pe (torch.Tensor): positional encoding with the shape of image_embeddings\n",
        "          sparse_prompt_embeddings (torch.Tensor): the embeddings of the points and boxes\n",
        "          dense_prompt_embeddings (torch.Tensor): the embeddings of the mask inputs\n",
        "          multimask_output (bool): Whether to return multiple masks or a single\n",
        "            mask.\n",
        "\n",
        "        Returns:\n",
        "          torch.Tensor: batched predicted masks\n",
        "          torch.Tensor: batched predictions of mask quality\n",
        "        \"\"\"\n",
        "        masks, iou_pred = self.predict_masks(\n",
        "            image_embeddings=image_embeddings,\n",
        "            image_pe=image_pe,\n",
        "            sparse_prompt_embeddings=sparse_prompt_embeddings,\n",
        "            dense_prompt_embeddings=dense_prompt_embeddings,\n",
        "        )\n",
        "\n",
        "        # Select the correct mask or masks for output\n",
        "        if multimask_output:\n",
        "            mask_slice = slice(1, None)\n",
        "        else:\n",
        "            mask_slice = slice(0, 1)\n",
        "        masks = masks[:, mask_slice, :, :, :]\n",
        "        iou_pred = iou_pred[:, mask_slice]\n",
        "\n",
        "        # Prepare output\n",
        "        return masks, iou_pred\n",
        "\n",
        "    def predict_masks(\n",
        "        self,\n",
        "        image_embeddings: torch.Tensor,\n",
        "        image_pe: torch.Tensor,\n",
        "        sparse_prompt_embeddings: torch.Tensor,\n",
        "        dense_prompt_embeddings: torch.Tensor,\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Predicts masks. See 'forward' for more details.\"\"\"\n",
        "        # Concatenate output tokens\n",
        "        output_tokens = torch.cat([self.iou_token.weight, self.mask_tokens.weight], dim=0)\n",
        "        output_tokens = output_tokens.unsqueeze(0).expand(sparse_prompt_embeddings.size(0), -1, -1)\n",
        "        tokens = torch.cat((output_tokens, sparse_prompt_embeddings), dim=1)\n",
        "\n",
        "        # Expand per-image data in batch direction to be per-mask\n",
        "        src = torch.repeat_interleave(image_embeddings, tokens.shape[0], dim=0)\n",
        "        src = src + dense_prompt_embeddings\n",
        "        pos_src = torch.repeat_interleave(image_pe, tokens.shape[0], dim=0)\n",
        "        b, c, h, w, d = src.shape\n",
        "\n",
        "        # Run the transformer\n",
        "        hs, src = self.transformer(src, pos_src, tokens)\n",
        "        iou_token_out = hs[:, 0, :]\n",
        "        mask_tokens_out = hs[:, 1 : (1 + self.num_mask_tokens), :]\n",
        "\n",
        "        # Upscale mask embeddings and predict masks using the mask tokens\n",
        "        src = src.transpose(1, 2).view(b, c, h, w, d)\n",
        "        upscaled_embedding = self.output_upscaling(src)\n",
        "        hyper_in_list: List[torch.Tensor] = []\n",
        "        #iterate\n",
        "        for i in range(self.num_mask_tokens):\n",
        "            hyper_in_list.append(self.output_hypernetworks_mlps[i](mask_tokens_out[:, i, :]))\n",
        "        hyper_in = torch.stack(hyper_in_list, dim=1)\n",
        "        #b, c, h, w = upscaled_embedding.shape this is likely if the upscaled embedding does not have the same size if altering upsampling\n",
        "        b, c, h, w, d = upscaled_embedding.shape\n",
        "        masks = (hyper_in @ upscaled_embedding.view(b, c, h * w * d)).view(b, -1, h, w, d)\n",
        "\n",
        "        # Generate mask quality predictions\n",
        "        iou_pred = self.iou_prediction_head(iou_token_out)\n",
        "\n",
        "        return masks, iou_pred\n",
        "\n",
        "\n",
        "# Lightly adapted from\n",
        "# https://github.com/facebookresearch/MaskFormer/blob/main/mask_former/modeling/transformer/transformer_predictor.py # noqa\n",
        "class MLP(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        hidden_dim: int,\n",
        "        output_dim: int,\n",
        "        num_layers: int,\n",
        "        sigmoid_output: bool = False,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        h = [hidden_dim] * (num_layers - 1)\n",
        "        self.layers = nn.ModuleList(\n",
        "            nn.Linear(n, k) for n, k in zip([input_dim] + h, h + [output_dim])\n",
        "        )\n",
        "        self.sigmoid_output = sigmoid_output\n",
        "\n",
        "    def forward(self, x):\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            x = F.relu(layer(x)) if i < self.num_layers - 1 else layer(x)\n",
        "        if self.sigmoid_output:\n",
        "            x = F.sigmoid(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "9L14PcGW-QBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "# All rights reserved.\n",
        "\n",
        "class AnishSalviModel(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_size: Tuple[int, int, int] = (64, 64, 64),\n",
        "        patch_size: Tuple[int, int, int] = (8, 8, 8),\n",
        "        in_chans: int = 1,\n",
        "        image_embed_dim: int = 768, #has to be 768?\n",
        "        image_encoder_depth: int = 12,\n",
        "        image_encoder_num_heads: int = 12,\n",
        "        image_encoder_mlp_ratio: int = 4,\n",
        "        image_encoder_out_chans: int = 512, #same?\n",
        "        prompt_encoder_embed_dim: int = 512, #same?\n",
        "        prompt_encoder_mask_in_chans: List = [1, 3, 5],\n",
        "        prompt_encoder_kernel_stride_size: List = [(2, 2, 2), (4, 4, 4)],\n",
        "        prompt_encoder_num_attention_heads: int = 4,\n",
        "        prompt_encoder_num_hidden_layers: int = 8,\n",
        "        prompt_encoder_projection_dim: int = 64,\n",
        "        prompt_encoder_intermediate_size: int = 64,\n",
        "        prompt_encoder_max_position_embeddings: int = 16,\n",
        "        transformer_depth: int = 16,\n",
        "        transformer_embedding_dim: int = 512, #same?\n",
        "        transformer_num_heads: int = 16,\n",
        "        transformer_mlp_dim: int = 8,\n",
        "        mask_decoder_kernel_stride_size: List = [(4, 4, 4), (2, 2, 2)],\n",
        "        mask_decoder_transformer_dim: List = [512, 512, 512],\n",
        "        mask_decoder_num_multimask_outputs: int = 3,\n",
        "        mask_decoder_num_layers: int = 3,\n",
        "        tokenizer: Optional[AutoTokenizer] = None\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        SAM predicts object masks from an image and input prompts.\n",
        "\n",
        "        Arguments:\n",
        "          image_encoder (ImageEncoderViT): The backbone used to encode the\n",
        "            image into image embeddings that allow for efficient mask prediction.\n",
        "          prompt_encoder (PromptEncoder): Encodes various types of input prompts.\n",
        "          transformer (TwoWayTransformer): Processes embeddings within mask_decoder\n",
        "          mask_decoder (MaskDecoder): Predicts masks from the image embeddings\n",
        "            and encoded prompts.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        #image encoder\n",
        "        self.image_encoder = ImageEncoderViT(img_size, patch_size, in_chans, image_embed_dim,\n",
        "                                image_encoder_depth, image_encoder_num_heads, image_encoder_mlp_ratio, image_encoder_out_chans)\n",
        "\n",
        "        #prompt encoder\n",
        "        self.prompt_encoder = PromptEncoder(prompt_encoder_embed_dim,\n",
        "                                            img_size, patch_size, prompt_encoder_mask_in_chans, prompt_encoder_kernel_stride_size,\n",
        "                                            prompt_encoder_num_attention_heads,\n",
        "                                            prompt_encoder_num_hidden_layers, prompt_encoder_projection_dim,\n",
        "                                            prompt_encoder_intermediate_size, prompt_encoder_max_position_embeddings, tokenizer)\n",
        "        #transformer\n",
        "        transformer = TwoWayTransformer(transformer_depth, transformer_embedding_dim,\n",
        "                                        transformer_num_heads, transformer_mlp_dim)\n",
        "        #mask decoder\n",
        "        self.mask_decoder = MaskDecoder(mask_decoder_kernel_stride_size, mask_decoder_transformer_dim, patch_size, transformer,\n",
        "                                        mask_decoder_num_multimask_outputs, mask_decoder_num_layers)\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        batched_input: List[Dict[str, Any]],\n",
        "        multimask_output: bool,\n",
        "    ) -> List[Dict[str, torch.Tensor]]:\n",
        "        \"\"\"\n",
        "        Predicts masks end-to-end from provided images and prompts.\n",
        "        If prompts are not known in advance, using ASMpredictor is\n",
        "        recommended over calling the model directly.\n",
        "\n",
        "        Arguments:\n",
        "          batched_input (list(dict)): A list over input images, each a\n",
        "            dictionary with the following keys. A prompt key can be\n",
        "            excluded if it is not present.\n",
        "              'image': The image as a torch tensor in CxHxWxD format,\n",
        "                already transformed for input to the model.\n",
        "              'point_coords': (torch.Tensor) Batched point prompts for\n",
        "                this image, with shape BxNx3. Already transformed to the\n",
        "                input frame of the model.\n",
        "              'point_labels': (torch.Tensor) Batched labels for point prompts,\n",
        "                with shape BxN.\n",
        "              'boxes': (torch.Tensor) Batched box inputs, with shape Bx6.\n",
        "                Already transformed to the input frame of the model.\n",
        "              'mask_inputs': (torch.Tensor) Batched mask inputs to the model,\n",
        "                in the form Bx1xHxWxD.\n",
        "          multimask_output (bool): Whether the model should predict multiple\n",
        "            disambiguating masks, or return a single mask.\n",
        "\n",
        "        Returns:\n",
        "          (list(dict)): A list over input images, where each element is\n",
        "            as dictionary with the following keys.\n",
        "              'iou_predictions': (torch.Tensor) The model's predictions\n",
        "                of mask quality, in shape BxC.\n",
        "              'low_res_logits': (torch.Tensor) Low resolution logits with\n",
        "                shape BxCxHxW. Can be passed as mask input\n",
        "                to subsequent iterations of prediction.\n",
        "        \"\"\"\n",
        "        input_images = torch.stack([x[\"image\"] for x in batched_input], dim=0)\n",
        "        image_embeddings = self.image_encoder(input_images)\n",
        "\n",
        "        outputs = []\n",
        "        for image_record, curr_embedding in zip(batched_input, image_embeddings):\n",
        "            #encode embeddings\n",
        "            sparse_embeddings, dense_embeddings = self.prompt_encoder(\n",
        "                points=(image_record[\"point_coords\"], image_record[\"point_labels\"]),\n",
        "                boxes=image_record.get(\"boxes\", None),\n",
        "                masks=image_record.get(\"mask_inputs\", None),\n",
        "                text=image_record.get(\"text\", None)\n",
        "            )\n",
        "            #decode embeddings\n",
        "            low_res_masks, iou_predictions = self.mask_decoder(\n",
        "                image_embeddings=curr_embedding.unsqueeze(0),\n",
        "                image_pe=self.prompt_encoder.get_dense_pe(),\n",
        "                sparse_prompt_embeddings=sparse_embeddings,\n",
        "                dense_prompt_embeddings=dense_embeddings,\n",
        "                multimask_output=multimask_output,\n",
        "            )\n",
        "            outputs.append(\n",
        "                {\n",
        "                    \"iou_predictions\": iou_predictions,\n",
        "                    \"logits\": low_res_masks,\n",
        "                }\n",
        "            )\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "4FJLneB5-SnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dice focal loss multilabel\n",
        "class DiceFocalIOULoss:\n",
        "  def __init__(self, include_background = True, to_onehot_y = False, thresh = 0.5,\n",
        "               gamma = 2.0, focal_weight = None, lambda_dice = 1.0, lambda_focal = 1.0, lambda_iou = 1.0):\n",
        "    #dice focal loss\n",
        "    self.loss_fn1 = monai.losses.DiceFocalLoss(include_background = include_background, to_onehot_y = to_onehot_y,\n",
        "                                               sigmoid = True, softmax = False,\n",
        "                                               gamma = gamma, focal_weight = focal_weight,\n",
        "                                                lambda_dice = lambda_dice, lambda_focal = lambda_focal)\n",
        "    self.fn2 = monai.metrics.MeanIoU(reduction = 'none')\n",
        "    #l1 loss\n",
        "    self.loss_fn3 = torch.nn.MSELoss()\n",
        "    #set\n",
        "    self.thresh = thresh\n",
        "    self.lambda_iou = lambda_iou\n",
        "\n",
        "  def __call__(self, batched_output, batched_input):\n",
        "    #init\n",
        "    loss_fn1 = 0\n",
        "    loss_fn3 = 0\n",
        "    #iterate y_pred, y_true\n",
        "    for i, (output, input) in enumerate(zip(batched_output, batched_input)):\n",
        "      #if sigmoid else softmax\n",
        "      y_pred = torch.swapaxes(output['logits'], 0, 1)\n",
        "      #y_true\n",
        "      y_true = torch.swapaxes(input['mask_inputs'], 0, 1)\n",
        "      #dice focal loss\n",
        "      loss_fn1 += self.loss_fn1(y_pred, y_true)\n",
        "      #proxy for iou loss\n",
        "      y_pred = torch.sigmoid(y_pred)\n",
        "      iou_y_true = self.fn2(torch.where(y_pred > self.thresh, 1, 0), y_true)\n",
        "      #apply\n",
        "      loss_fn3 += self.loss_fn3(torch.sigmoid(output['iou_predictions']), iou_y_true.T)\n",
        "\n",
        "    #divide\n",
        "    return (loss_fn1 + self.lambda_iou * loss_fn3) / len(batched_input)"
      ],
      "metadata": {
        "id": "DoIMjdeI_VsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#init\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "else:\n",
        "  device = 'cpu'\n",
        "\n",
        "#init\n",
        "model = AnishSalviModel()\n",
        "criterion = DiceFocalIOULoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = 5e-5, weight_decay = 0.0)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 15, gamma=0.7, verbose=True)\n",
        "\n",
        "#send\n",
        "model.to(device)\n",
        "\n",
        "#input data\n",
        "\n",
        "#boxes\n",
        "boxes = torch.Tensor([\n",
        "    [16, 16, 16, 36, 36, 36],\n",
        "    [0, 0, 0, 63, 63, 63],\n",
        "     [20, 20, 20, 30, 30, 30]])\n",
        "\n",
        "#get label\n",
        "label = torch.zeros((64, 64, 64))\n",
        "label[16:36,16:36,16:36] = 1\n",
        "label[20:30,20:30,20:30] = 2\n",
        "\n",
        "#point coords\n",
        "point_coords = torch.Tensor([[[18, 18, 18], [33, 33, 33]], [[4, 4, 4], [60, 60, 60]], [[24, 24, 24], [26, 26, 26]]])\n",
        "#point_coords = torch.Tensor([[[4, 4, 4], [60, 60, 60]], [[18, 18, 18], [33, 33, 33]], [[24, 24, 24], [26, 26, 26]]])\n",
        "\n",
        "#point labels\n",
        "point_labels = torch.Tensor([[1, 1], [1, 1], [1, 1]]) #0 if outside and -1 if background; in multiclass likely 0s and 1s\n",
        "\n",
        "#mask inputs\n",
        "mask_inputs = torch.zeros((3, 1, 64, 64, 64))\n",
        "mask_inputs[0, 0, ] = torch.where(label >= 1, 1, 0)\n",
        "mask_inputs[1, 0, ] = torch.where(label == 0, 1, 0)\n",
        "mask_inputs[2, 0, ] = torch.where(label == 2, 1, 0)\n",
        "\n",
        "#image\n",
        "image = (label - label.mean()) / label.std()\n",
        "#image add channel\n",
        "image = torch.unsqueeze(image, 0)\n",
        "\n",
        "#text\n",
        "text = ['lungs', 'aorta', 'brain']\n",
        "\n",
        "#get dict\n",
        "dict0 = {\n",
        "    'image': image.to(device),\n",
        "    'point_coords': None, #, point_coords.to(device),\n",
        "    'point_labels': None, #point_labels.to(device),\n",
        "    'boxes': None, #boxes.to(device),\n",
        "    'mask_inputs': mask_inputs.to(device),\n",
        "    'text': text\n",
        "    }\n",
        "\n",
        "#get batch\n",
        "batched_input = [dict0] #[dict0, dict0]\n",
        "\n",
        "#iterate\n",
        "for i in range(500):\n",
        "  #zero optimizer\n",
        "  optimizer.zero_grad()\n",
        "  #cast\n",
        "  #with torch.amp.autocast(device, torch.float16):\n",
        "  #forward pass\n",
        "  batched_output = model(batched_input, False)\n",
        "  #compute loss\n",
        "  loss = criterion(batched_output, batched_input)\n",
        "  #check backwards\n",
        "  loss.backward()\n",
        "  #step\n",
        "  optimizer.step()\n",
        "  #step\n",
        "  scheduler.step()\n",
        "  #print\n",
        "  print(loss.item())"
      ],
      "metadata": {
        "id": "DBatvOoX_f9P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2a8298545c884e2692642af82eb0065c",
            "e7fb4f214264433ca961a00857f7b61e",
            "a3eebaf346084512b2b06743a00d8edb",
            "04c5c1c372dd44b0bc9119f650906ad8",
            "eef8ab40bdb54272bed2f1ca91d9ff13",
            "c71530b099e4492e9febb4c2e67d0d73",
            "c55acf7ac97c436ba78da128506d7307",
            "b4b5a34dd51e49bba7eecc0c2f44b89a",
            "8f98100e96244884b476ac4ba9f4b5a7",
            "36a9af3a425e4f2a98d185336201099a",
            "e99bc09b170a44f08e51995c3c1cce00",
            "47ef8ced340249818293db2953421f14",
            "3cbe5a260fc34aa79627ff85c023c727",
            "a460434b56e94587a7eedaf6ce974b53",
            "585f3efd8a9342578a69b47e7e4cb651",
            "1f75ddd95f304d86bfab7b11080b3657",
            "8ee83f046f204f8ba5bde9743335e921",
            "445e4dfbbcbd4905b9c606d6a3fcfae4",
            "3167278526aa4b0e9e995a5291d07d11",
            "149d772e6db24ebd8b404a269bff98bd",
            "b652853bf46b49c593ccf4876cc75b5f",
            "9062352892064fc8b92ab7382e033a19",
            "54626fc2f67d433c92ac34ba64bab08c",
            "357b410c119b4ec6be5b67c8854e1ea9",
            "a380f22dcd9348208815ef37772d0b18",
            "b30d5e60d26a42c89d0a77fbee1e86ed",
            "349bf636bfda46ccb23fef4b894c6fbc",
            "822e6bb406714f54bd8a682453dc372f",
            "7ae7261d55ab40a29d49a882fa882278",
            "3d39f7d07b5e4845857a4ae5e65cd9e6",
            "0884bdee31754ccdbf38ba22f7314027",
            "fc4d85f1c23c46ffbb83199d432c6f54",
            "62e50802898c4d5ca34562dd4c18c92e",
            "b517aeeff6fd467897517206bbcc04c5",
            "3fa5eac74ac74d43b6d50fd3638d4fb0",
            "d6ccdfe952394a68a810ddf217211c82",
            "efa944bcbac44f17839bc1100e9f9725",
            "066978240f244f0b82b5eb7928ee353c",
            "a745393ad6e145a39fc2a8aeed8a55b4",
            "1025f37b2f144bd199c612eda55c25be",
            "da4048cc15d143ff925dfe4d5a49d7dd",
            "3d18116152c548419fc4b59669b8efbe",
            "6901000b2ee54a79954228f8e438b69b",
            "8471da42a88249669bdf9cb68074b395",
            "c707985689b741ebbed30fd1e2fccf49",
            "5a63ae8dab834217b154efa90ddf0fb5",
            "d78a1adfcddb464292abdaf3104fdad7",
            "708463985d0740fc9ba121ecf69840d8",
            "13672eb1c5764104a1936359d66d1e9d",
            "f114bb21297b4f8d91d9a566d5636ac1",
            "4f47e1cbcd284a88b09f1167e7c486c6",
            "9a9def45cc1d4870b7f6d3b2b3fea129",
            "d3935615535b4937ac7c090c00317855",
            "a0ffa3575cc04c7aa15abcbf86a0f7a6",
            "05d6978e78da4893a23ecc853d5ad66a"
          ]
        },
        "outputId": "39ec1daa-81a5-4a56-f111-2523fcd4c5d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a8298545c884e2692642af82eb0065c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/862k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47ef8ced340249818293db2953421f14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54626fc2f67d433c92ac34ba64bab08c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b517aeeff6fd467897517206bbcc04c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/568 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c707985689b741ebbed30fd1e2fccf49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adjusting learning rate of group 0 to 5.0000e-05.\n",
            "Adjusting learning rate of group 0 to 5.0000e-05.\n",
            "1.1082812547683716\n",
            "Adjusting learning rate of group 0 to 5.0000e-05.\n",
            "1.030069351196289\n",
            "Adjusting learning rate of group 0 to 5.0000e-05.\n",
            "0.9907459616661072\n",
            "Adjusting learning rate of group 0 to 5.0000e-05.\n",
            "0.9976308941841125\n",
            "Adjusting learning rate of group 0 to 5.0000e-05.\n",
            "0.9677148461341858\n",
            "Adjusting learning rate of group 0 to 5.0000e-05.\n",
            "1.0263516902923584\n",
            "Adjusting learning rate of group 0 to 5.0000e-05.\n",
            "1.0544960498809814\n",
            "Adjusting learning rate of group 0 to 5.0000e-05.\n",
            "0.9334794878959656\n",
            "Adjusting learning rate of group 0 to 5.0000e-05.\n",
            "0.9175755977630615\n",
            "Adjusting learning rate of group 0 to 5.0000e-05.\n",
            "0.8487032651901245\n",
            "Adjusting learning rate of group 0 to 5.0000e-05.\n",
            "0.8234428763389587\n",
            "Adjusting learning rate of group 0 to 5.0000e-05.\n",
            "0.8005256056785583\n",
            "Adjusting learning rate of group 0 to 5.0000e-05.\n",
            "0.7805685997009277\n",
            "Adjusting learning rate of group 0 to 5.0000e-05.\n",
            "0.769184947013855\n",
            "Adjusting learning rate of group 0 to 3.5000e-05.\n",
            "0.7600361704826355\n",
            "Adjusting learning rate of group 0 to 3.5000e-05.\n",
            "0.7508593797683716\n",
            "Adjusting learning rate of group 0 to 3.5000e-05.\n",
            "0.7466437816619873\n",
            "Adjusting learning rate of group 0 to 3.5000e-05.\n",
            "0.7395986914634705\n",
            "Adjusting learning rate of group 0 to 3.5000e-05.\n",
            "0.7315877676010132\n",
            "Adjusting learning rate of group 0 to 3.5000e-05.\n",
            "0.7167767286300659\n",
            "Adjusting learning rate of group 0 to 3.5000e-05.\n",
            "0.7159423828125\n",
            "Adjusting learning rate of group 0 to 3.5000e-05.\n",
            "0.708652675151825\n",
            "Adjusting learning rate of group 0 to 3.5000e-05.\n",
            "0.679876983165741\n",
            "Adjusting learning rate of group 0 to 3.5000e-05.\n",
            "0.7559160590171814\n",
            "Adjusting learning rate of group 0 to 3.5000e-05.\n",
            "0.6206218600273132\n",
            "Adjusting learning rate of group 0 to 3.5000e-05.\n",
            "0.5964438319206238\n",
            "Adjusting learning rate of group 0 to 3.5000e-05.\n",
            "0.4971470534801483\n",
            "Adjusting learning rate of group 0 to 3.5000e-05.\n",
            "0.4697442948818207\n",
            "Adjusting learning rate of group 0 to 3.5000e-05.\n",
            "0.4191782474517822\n",
            "Adjusting learning rate of group 0 to 2.4500e-05.\n",
            "0.3876841366291046\n",
            "Adjusting learning rate of group 0 to 2.4500e-05.\n",
            "0.3739995062351227\n",
            "Adjusting learning rate of group 0 to 2.4500e-05.\n",
            "0.3444867730140686\n",
            "Adjusting learning rate of group 0 to 2.4500e-05.\n",
            "0.31925928592681885\n",
            "Adjusting learning rate of group 0 to 2.4500e-05.\n",
            "0.3087584376335144\n",
            "Adjusting learning rate of group 0 to 2.4500e-05.\n",
            "0.2698865532875061\n",
            "Adjusting learning rate of group 0 to 2.4500e-05.\n",
            "0.2513604760169983\n",
            "Adjusting learning rate of group 0 to 2.4500e-05.\n",
            "0.4857097566127777\n",
            "Adjusting learning rate of group 0 to 2.4500e-05.\n",
            "0.23556023836135864\n",
            "Adjusting learning rate of group 0 to 2.4500e-05.\n",
            "0.23025046288967133\n",
            "Adjusting learning rate of group 0 to 2.4500e-05.\n",
            "0.20539376139640808\n",
            "Adjusting learning rate of group 0 to 2.4500e-05.\n",
            "0.1983756422996521\n",
            "Adjusting learning rate of group 0 to 2.4500e-05.\n",
            "0.19810014963150024\n",
            "Adjusting learning rate of group 0 to 2.4500e-05.\n",
            "0.1779664158821106\n",
            "Adjusting learning rate of group 0 to 2.4500e-05.\n",
            "0.16127225756645203\n",
            "Adjusting learning rate of group 0 to 1.7150e-05.\n",
            "0.14930205047130585\n",
            "Adjusting learning rate of group 0 to 1.7150e-05.\n",
            "0.13680130243301392\n",
            "Adjusting learning rate of group 0 to 1.7150e-05.\n",
            "0.11780603229999542\n",
            "Adjusting learning rate of group 0 to 1.7150e-05.\n",
            "0.11722186207771301\n",
            "Adjusting learning rate of group 0 to 1.7150e-05.\n",
            "0.10948644578456879\n",
            "Adjusting learning rate of group 0 to 1.7150e-05.\n",
            "0.09971734881401062\n",
            "Adjusting learning rate of group 0 to 1.7150e-05.\n",
            "0.09826312959194183\n",
            "Adjusting learning rate of group 0 to 1.7150e-05.\n",
            "0.09355995059013367\n",
            "Adjusting learning rate of group 0 to 1.7150e-05.\n",
            "0.0863587036728859\n",
            "Adjusting learning rate of group 0 to 1.7150e-05.\n",
            "0.08252809941768646\n",
            "Adjusting learning rate of group 0 to 1.7150e-05.\n",
            "0.07975168526172638\n",
            "Adjusting learning rate of group 0 to 1.7150e-05.\n",
            "0.07638061791658401\n",
            "Adjusting learning rate of group 0 to 1.7150e-05.\n",
            "0.07263225317001343\n",
            "Adjusting learning rate of group 0 to 1.7150e-05.\n",
            "0.07090750336647034\n",
            "Adjusting learning rate of group 0 to 1.7150e-05.\n",
            "0.06924819946289062\n",
            "Adjusting learning rate of group 0 to 1.2005e-05.\n",
            "0.06611154973506927\n",
            "Adjusting learning rate of group 0 to 1.2005e-05.\n",
            "0.06332775950431824\n",
            "Adjusting learning rate of group 0 to 1.2005e-05.\n",
            "0.06218031421303749\n",
            "Adjusting learning rate of group 0 to 1.2005e-05.\n",
            "0.06132618710398674\n",
            "Adjusting learning rate of group 0 to 1.2005e-05.\n",
            "0.060291826725006104\n",
            "Adjusting learning rate of group 0 to 1.2005e-05.\n",
            "0.05903945863246918\n",
            "Adjusting learning rate of group 0 to 1.2005e-05.\n",
            "0.05774540454149246\n",
            "Adjusting learning rate of group 0 to 1.2005e-05.\n",
            "0.05659305304288864\n",
            "Adjusting learning rate of group 0 to 1.2005e-05.\n",
            "0.05559100955724716\n",
            "Adjusting learning rate of group 0 to 1.2005e-05.\n",
            "0.05468333512544632\n",
            "Adjusting learning rate of group 0 to 1.2005e-05.\n",
            "0.05381960794329643\n",
            "Adjusting learning rate of group 0 to 1.2005e-05.\n",
            "0.052983492612838745\n",
            "Adjusting learning rate of group 0 to 1.2005e-05.\n",
            "0.05220453813672066\n",
            "Adjusting learning rate of group 0 to 1.2005e-05.\n",
            "0.05151892453432083\n",
            "Adjusting learning rate of group 0 to 1.2005e-05.\n",
            "0.05092276632785797\n",
            "Adjusting learning rate of group 0 to 8.4035e-06.\n",
            "0.05039002001285553\n",
            "Adjusting learning rate of group 0 to 8.4035e-06.\n",
            "0.04989149793982506\n",
            "Adjusting learning rate of group 0 to 8.4035e-06.\n",
            "0.049546174705028534\n",
            "Adjusting learning rate of group 0 to 8.4035e-06.\n",
            "0.04919654503464699\n",
            "Adjusting learning rate of group 0 to 8.4035e-06.\n",
            "0.048846881836652756\n",
            "Adjusting learning rate of group 0 to 8.4035e-06.\n",
            "0.04850344732403755\n",
            "Adjusting learning rate of group 0 to 8.4035e-06.\n",
            "0.04817568138241768\n",
            "Adjusting learning rate of group 0 to 8.4035e-06.\n",
            "0.04786749556660652\n",
            "Adjusting learning rate of group 0 to 8.4035e-06.\n",
            "0.047582317143678665\n",
            "Adjusting learning rate of group 0 to 8.4035e-06.\n",
            "0.047317925840616226\n",
            "Adjusting learning rate of group 0 to 8.4035e-06.\n",
            "0.04706805199384689\n",
            "Adjusting learning rate of group 0 to 8.4035e-06.\n",
            "0.04682307690382004\n",
            "Adjusting learning rate of group 0 to 8.4035e-06.\n",
            "0.0465821772813797\n",
            "Adjusting learning rate of group 0 to 8.4035e-06.\n",
            "0.04634229093790054\n",
            "Adjusting learning rate of group 0 to 8.4035e-06.\n",
            "0.046102315187454224\n",
            "Adjusting learning rate of group 0 to 5.8824e-06.\n",
            "0.045866359025239944\n",
            "Adjusting learning rate of group 0 to 5.8824e-06.\n",
            "0.04563506320118904\n",
            "Adjusting learning rate of group 0 to 5.8824e-06.\n",
            "0.0454765260219574\n",
            "Adjusting learning rate of group 0 to 5.8824e-06.\n",
            "0.04532107338309288\n",
            "Adjusting learning rate of group 0 to 5.8824e-06.\n",
            "0.04516884684562683\n",
            "Adjusting learning rate of group 0 to 5.8824e-06.\n",
            "0.045019932091236115\n",
            "Adjusting learning rate of group 0 to 5.8824e-06.\n",
            "0.04487362504005432\n",
            "Adjusting learning rate of group 0 to 5.8824e-06.\n",
            "0.04472934454679489\n",
            "Adjusting learning rate of group 0 to 5.8824e-06.\n",
            "0.044586651027202606\n",
            "Adjusting learning rate of group 0 to 5.8824e-06.\n",
            "0.044444747269153595\n",
            "Adjusting learning rate of group 0 to 5.8824e-06.\n",
            "0.04430294409394264\n",
            "Adjusting learning rate of group 0 to 5.8824e-06.\n",
            "0.04416082799434662\n",
            "Adjusting learning rate of group 0 to 5.8824e-06.\n",
            "0.044016819447278976\n",
            "Adjusting learning rate of group 0 to 5.8824e-06.\n",
            "0.04386957734823227\n",
            "Adjusting learning rate of group 0 to 5.8824e-06.\n",
            "0.0437166690826416\n",
            "Adjusting learning rate of group 0 to 4.1177e-06.\n",
            "0.043554194271564484\n",
            "Adjusting learning rate of group 0 to 4.1177e-06.\n",
            "0.04337619990110397\n",
            "Adjusting learning rate of group 0 to 4.1177e-06.\n",
            "0.043236829340457916\n",
            "Adjusting learning rate of group 0 to 4.1177e-06.\n",
            "0.043080754578113556\n",
            "Adjusting learning rate of group 0 to 4.1177e-06.\n",
            "0.042907439172267914\n",
            "Adjusting learning rate of group 0 to 4.1177e-06.\n",
            "0.042891185730695724\n",
            "Adjusting learning rate of group 0 to 4.1177e-06.\n",
            "0.04294324666261673\n",
            "Adjusting learning rate of group 0 to 4.1177e-06.\n",
            "0.04284262657165527\n",
            "Adjusting learning rate of group 0 to 4.1177e-06.\n",
            "0.04270324110984802\n",
            "Adjusting learning rate of group 0 to 4.1177e-06.\n",
            "0.04256531596183777\n",
            "Adjusting learning rate of group 0 to 4.1177e-06.\n",
            "0.04241219907999039\n",
            "Adjusting learning rate of group 0 to 4.1177e-06.\n",
            "0.04224414750933647\n",
            "Adjusting learning rate of group 0 to 4.1177e-06.\n",
            "0.042073220014572144\n",
            "Adjusting learning rate of group 0 to 4.1177e-06.\n",
            "0.04191110283136368\n",
            "Adjusting learning rate of group 0 to 4.1177e-06.\n",
            "0.04176343232393265\n",
            "Adjusting learning rate of group 0 to 2.8824e-06.\n",
            "0.04162907600402832\n",
            "Adjusting learning rate of group 0 to 2.8824e-06.\n",
            "0.041503917425870895\n",
            "Adjusting learning rate of group 0 to 2.8824e-06.\n",
            "0.04141901805996895\n",
            "Adjusting learning rate of group 0 to 2.8824e-06.\n",
            "0.0413348488509655\n",
            "Adjusting learning rate of group 0 to 2.8824e-06.\n",
            "0.04125067964196205\n",
            "Adjusting learning rate of group 0 to 2.8824e-06.\n",
            "0.04116642847657204\n",
            "Adjusting learning rate of group 0 to 2.8824e-06.\n",
            "0.04108237475156784\n",
            "Adjusting learning rate of group 0 to 2.8824e-06.\n",
            "0.04099901393055916\n",
            "Adjusting learning rate of group 0 to 2.8824e-06.\n",
            "0.04091662913560867\n",
            "Adjusting learning rate of group 0 to 2.8824e-06.\n",
            "0.0408354289829731\n",
            "Adjusting learning rate of group 0 to 2.8824e-06.\n",
            "0.04075556620955467\n",
            "Adjusting learning rate of group 0 to 2.8824e-06.\n",
            "0.04067693278193474\n",
            "Adjusting learning rate of group 0 to 2.8824e-06.\n",
            "0.040599316358566284\n",
            "Adjusting learning rate of group 0 to 2.8824e-06.\n",
            "0.040522441267967224\n",
            "Adjusting learning rate of group 0 to 2.8824e-06.\n",
            "0.040446024388074875\n",
            "Adjusting learning rate of group 0 to 2.0177e-06.\n",
            "0.04036994278430939\n",
            "Adjusting learning rate of group 0 to 2.0177e-06.\n",
            "0.040293797850608826\n",
            "Adjusting learning rate of group 0 to 2.0177e-06.\n",
            "0.040240414440631866\n",
            "Adjusting learning rate of group 0 to 2.0177e-06.\n",
            "0.04018672555685043\n",
            "Adjusting learning rate of group 0 to 2.0177e-06.\n",
            "0.04013287276029587\n",
            "Adjusting learning rate of group 0 to 2.0177e-06.\n",
            "0.04007875919342041\n",
            "Adjusting learning rate of group 0 to 2.0177e-06.\n",
            "0.04002438485622406\n",
            "Adjusting learning rate of group 0 to 2.0177e-06.\n",
            "0.03996967896819115\n",
            "Adjusting learning rate of group 0 to 2.0177e-06.\n",
            "0.03991474211215973\n",
            "Adjusting learning rate of group 0 to 2.0177e-06.\n",
            "0.039859578013420105\n",
            "Adjusting learning rate of group 0 to 2.0177e-06.\n",
            "0.03980416804552078\n",
            "Adjusting learning rate of group 0 to 2.0177e-06.\n",
            "0.039748433977365494\n",
            "Adjusting learning rate of group 0 to 2.0177e-06.\n",
            "0.03969249501824379\n",
            "Adjusting learning rate of group 0 to 2.0177e-06.\n",
            "0.039636194705963135\n",
            "Adjusting learning rate of group 0 to 2.0177e-06.\n",
            "0.03957972675561905\n",
            "Adjusting learning rate of group 0 to 1.4124e-06.\n",
            "0.03952285274863243\n",
            "Adjusting learning rate of group 0 to 1.4124e-06.\n",
            "0.039465826004743576\n",
            "Adjusting learning rate of group 0 to 1.4124e-06.\n",
            "0.039425574243068695\n",
            "Adjusting learning rate of group 0 to 1.4124e-06.\n",
            "0.039385151118040085\n",
            "Adjusting learning rate of group 0 to 1.4124e-06.\n",
            "0.039344608783721924\n",
            "Adjusting learning rate of group 0 to 1.4124e-06.\n",
            "0.03930364176630974\n",
            "Adjusting learning rate of group 0 to 1.4124e-06.\n",
            "0.039262596517801285\n",
            "Adjusting learning rate of group 0 to 1.4124e-06.\n",
            "0.03922129049897194\n",
            "Adjusting learning rate of group 0 to 1.4124e-06.\n",
            "0.03917969390749931\n",
            "Adjusting learning rate of group 0 to 1.4124e-06.\n",
            "0.03913787752389908\n",
            "Adjusting learning rate of group 0 to 1.4124e-06.\n",
            "0.03909582272171974\n",
            "Adjusting learning rate of group 0 to 1.4124e-06.\n",
            "0.03905359283089638\n",
            "Adjusting learning rate of group 0 to 1.4124e-06.\n",
            "0.039011016488075256\n",
            "Adjusting learning rate of group 0 to 1.4124e-06.\n",
            "0.03896811604499817\n",
            "Adjusting learning rate of group 0 to 1.4124e-06.\n",
            "0.03892507031559944\n",
            "Adjusting learning rate of group 0 to 9.8866e-07.\n",
            "0.038881730288267136\n",
            "Adjusting learning rate of group 0 to 9.8866e-07.\n",
            "0.03883804380893707\n",
            "Adjusting learning rate of group 0 to 9.8866e-07.\n",
            "0.03880731016397476\n",
            "Adjusting learning rate of group 0 to 9.8866e-07.\n",
            "0.03877643123269081\n",
            "Adjusting learning rate of group 0 to 9.8866e-07.\n",
            "0.03874531015753746\n",
            "Adjusting learning rate of group 0 to 9.8866e-07.\n",
            "0.03871404752135277\n",
            "Adjusting learning rate of group 0 to 9.8866e-07.\n",
            "0.03868265450000763\n",
            "Adjusting learning rate of group 0 to 9.8866e-07.\n",
            "0.038651008158922195\n",
            "Adjusting learning rate of group 0 to 9.8866e-07.\n",
            "0.0386192724108696\n",
            "Adjusting learning rate of group 0 to 9.8866e-07.\n",
            "0.03858727216720581\n",
            "Adjusting learning rate of group 0 to 9.8866e-07.\n",
            "0.03855511546134949\n",
            "Adjusting learning rate of group 0 to 9.8866e-07.\n",
            "0.03852275013923645\n",
            "Adjusting learning rate of group 0 to 9.8866e-07.\n",
            "0.038490183651447296\n",
            "Adjusting learning rate of group 0 to 9.8866e-07.\n",
            "0.03845744952559471\n",
            "Adjusting learning rate of group 0 to 9.8866e-07.\n",
            "0.03842451050877571\n",
            "Adjusting learning rate of group 0 to 6.9206e-07.\n",
            "0.0383913516998291\n",
            "Adjusting learning rate of group 0 to 6.9206e-07.\n",
            "0.03835803270339966\n",
            "Adjusting learning rate of group 0 to 6.9206e-07.\n",
            "0.038334544748067856\n",
            "Adjusting learning rate of group 0 to 6.9206e-07.\n",
            "0.03831098973751068\n",
            "Adjusting learning rate of group 0 to 6.9206e-07.\n",
            "0.038287315517663956\n",
            "Adjusting learning rate of group 0 to 6.9206e-07.\n",
            "0.03826353698968887\n",
            "Adjusting learning rate of group 0 to 6.9206e-07.\n",
            "0.03823957219719887\n",
            "Adjusting learning rate of group 0 to 6.9206e-07.\n",
            "0.03821549564599991\n",
            "Adjusting learning rate of group 0 to 6.9206e-07.\n",
            "0.038191355764865875\n",
            "Adjusting learning rate of group 0 to 6.9206e-07.\n",
            "0.03816710785031319\n",
            "Adjusting learning rate of group 0 to 6.9206e-07.\n",
            "0.03814265877008438\n",
            "Adjusting learning rate of group 0 to 6.9206e-07.\n",
            "0.038118138909339905\n",
            "Adjusting learning rate of group 0 to 6.9206e-07.\n",
            "0.03809351101517677\n",
            "Adjusting learning rate of group 0 to 6.9206e-07.\n",
            "0.03806879371404648\n",
            "Adjusting learning rate of group 0 to 6.9206e-07.\n",
            "0.03804389759898186\n",
            "Adjusting learning rate of group 0 to 4.8445e-07.\n",
            "0.038018885999917984\n",
            "Adjusting learning rate of group 0 to 4.8445e-07.\n",
            "0.03799370303750038\n",
            "Adjusting learning rate of group 0 to 4.8445e-07.\n",
            "0.03797604888677597\n",
            "Adjusting learning rate of group 0 to 4.8445e-07.\n",
            "0.03795836493372917\n",
            "Adjusting learning rate of group 0 to 4.8445e-07.\n",
            "0.03794054687023163\n",
            "Adjusting learning rate of group 0 to 4.8445e-07.\n",
            "0.03792260214686394\n",
            "Adjusting learning rate of group 0 to 4.8445e-07.\n",
            "0.03790465369820595\n",
            "Adjusting learning rate of group 0 to 4.8445e-07.\n",
            "0.0378866046667099\n",
            "Adjusting learning rate of group 0 to 4.8445e-07.\n",
            "0.0378684476017952\n",
            "Adjusting learning rate of group 0 to 4.8445e-07.\n",
            "0.037850216031074524\n",
            "Adjusting learning rate of group 0 to 4.8445e-07.\n",
            "0.03783196210861206\n",
            "Adjusting learning rate of group 0 to 4.8445e-07.\n",
            "0.03781363368034363\n",
            "Adjusting learning rate of group 0 to 4.8445e-07.\n",
            "0.037795133888721466\n",
            "Adjusting learning rate of group 0 to 4.8445e-07.\n",
            "0.037776634097099304\n",
            "Adjusting learning rate of group 0 to 4.8445e-07.\n",
            "0.03775807097554207\n",
            "Adjusting learning rate of group 0 to 3.3911e-07.\n",
            "0.03773937374353409\n",
            "Adjusting learning rate of group 0 to 3.3911e-07.\n",
            "0.037720635533332825\n",
            "Adjusting learning rate of group 0 to 3.3911e-07.\n",
            "0.03770748898386955\n",
            "Adjusting learning rate of group 0 to 3.3911e-07.\n",
            "0.03769426420331001\n",
            "Adjusting learning rate of group 0 to 3.3911e-07.\n",
            "0.037681009620428085\n",
            "Adjusting learning rate of group 0 to 3.3911e-07.\n",
            "0.037667643278837204\n",
            "Adjusting learning rate of group 0 to 3.3911e-07.\n",
            "0.03765425086021423\n",
            "Adjusting learning rate of group 0 to 3.3911e-07.\n",
            "0.037640899419784546\n",
            "Adjusting learning rate of group 0 to 3.3911e-07.\n",
            "0.03762739151716232\n",
            "Adjusting learning rate of group 0 to 3.3911e-07.\n",
            "0.037613868713378906\n",
            "Adjusting learning rate of group 0 to 3.3911e-07.\n",
            "0.037600308656692505\n",
            "Adjusting learning rate of group 0 to 3.3911e-07.\n",
            "0.03758666291832924\n",
            "Adjusting learning rate of group 0 to 3.3911e-07.\n",
            "0.037573035806417465\n",
            "Adjusting learning rate of group 0 to 3.3911e-07.\n",
            "0.03755930811166763\n",
            "Adjusting learning rate of group 0 to 3.3911e-07.\n",
            "0.037545591592788696\n",
            "Adjusting learning rate of group 0 to 2.3738e-07.\n",
            "0.03753174841403961\n",
            "Adjusting learning rate of group 0 to 2.3738e-07.\n",
            "0.03751790151000023\n",
            "Adjusting learning rate of group 0 to 2.3738e-07.\n",
            "0.037508174777030945\n",
            "Adjusting learning rate of group 0 to 2.3738e-07.\n",
            "0.03749839588999748\n",
            "Adjusting learning rate of group 0 to 2.3738e-07.\n",
            "0.03748859092593193\n",
            "Adjusting learning rate of group 0 to 2.3738e-07.\n",
            "0.03747876361012459\n",
            "Adjusting learning rate of group 0 to 2.3738e-07.\n",
            "0.037468984723091125\n",
            "Adjusting learning rate of group 0 to 2.3738e-07.\n",
            "0.03745906054973602\n",
            "Adjusting learning rate of group 0 to 2.3738e-07.\n",
            "0.037449173629283905\n",
            "Adjusting learning rate of group 0 to 2.3738e-07.\n",
            "0.03743923828005791\n",
            "Adjusting learning rate of group 0 to 2.3738e-07.\n",
            "0.03742927685379982\n",
            "Adjusting learning rate of group 0 to 2.3738e-07.\n",
            "0.037419311702251434\n",
            "Adjusting learning rate of group 0 to 2.3738e-07.\n",
            "0.03740929812192917\n",
            "Adjusting learning rate of group 0 to 2.3738e-07.\n",
            "0.03739923611283302\n",
            "Adjusting learning rate of group 0 to 2.3738e-07.\n",
            "0.03738917410373688\n",
            "Adjusting learning rate of group 0 to 1.6616e-07.\n",
            "0.03737907111644745\n",
            "Adjusting learning rate of group 0 to 1.6616e-07.\n",
            "0.03736892342567444\n",
            "Adjusting learning rate of group 0 to 1.6616e-07.\n",
            "0.03736183047294617\n",
            "Adjusting learning rate of group 0 to 1.6616e-07.\n",
            "0.03735465556383133\n",
            "Adjusting learning rate of group 0 to 1.6616e-07.\n",
            "0.03734754025936127\n",
            "Adjusting learning rate of group 0 to 1.6616e-07.\n",
            "0.037340354174375534\n",
            "Adjusting learning rate of group 0 to 1.6616e-07.\n",
            "0.03733321651816368\n",
            "Adjusting learning rate of group 0 to 1.6616e-07.\n",
            "0.03732600808143616\n",
            "Adjusting learning rate of group 0 to 1.6616e-07.\n",
            "0.037318743765354156\n",
            "Adjusting learning rate of group 0 to 1.6616e-07.\n",
            "0.03731149062514305\n",
            "Adjusting learning rate of group 0 to 1.6616e-07.\n",
            "0.03730425611138344\n",
            "Adjusting learning rate of group 0 to 1.6616e-07.\n",
            "0.03729695826768875\n",
            "Adjusting learning rate of group 0 to 1.6616e-07.\n",
            "0.037289686501026154\n",
            "Adjusting learning rate of group 0 to 1.6616e-07.\n",
            "0.03728237375617027\n",
            "Adjusting learning rate of group 0 to 1.6616e-07.\n",
            "0.03727506101131439\n",
            "Adjusting learning rate of group 0 to 1.1632e-07.\n",
            "0.03726770728826523\n",
            "Adjusting learning rate of group 0 to 1.1632e-07.\n",
            "0.03726036101579666\n",
            "Adjusting learning rate of group 0 to 1.1632e-07.\n",
            "0.03725520893931389\n",
            "Adjusting learning rate of group 0 to 1.1632e-07.\n",
            "0.037250030785799026\n",
            "Adjusting learning rate of group 0 to 1.1632e-07.\n",
            "0.03724484145641327\n",
            "Adjusting learning rate of group 0 to 1.1632e-07.\n",
            "0.03723962604999542\n",
            "Adjusting learning rate of group 0 to 1.1632e-07.\n",
            "0.03723444789648056\n",
            "Adjusting learning rate of group 0 to 1.1632e-07.\n",
            "0.03722923621535301\n",
            "Adjusting learning rate of group 0 to 1.1632e-07.\n",
            "0.0372239388525486\n",
            "Adjusting learning rate of group 0 to 1.1632e-07.\n",
            "0.03721873089671135\n",
            "Adjusting learning rate of group 0 to 1.1632e-07.\n",
            "0.03721345216035843\n",
            "Adjusting learning rate of group 0 to 1.1632e-07.\n",
            "0.037208192050457\n",
            "Adjusting learning rate of group 0 to 1.1632e-07.\n",
            "0.03720288351178169\n",
            "Adjusting learning rate of group 0 to 1.1632e-07.\n",
            "0.03719765320420265\n",
            "Adjusting learning rate of group 0 to 1.1632e-07.\n",
            "0.03719232976436615\n",
            "Adjusting learning rate of group 0 to 8.1421e-08.\n",
            "0.037187039852142334\n",
            "Adjusting learning rate of group 0 to 8.1421e-08.\n",
            "0.03718166798353195\n",
            "Adjusting learning rate of group 0 to 8.1421e-08.\n",
            "0.03717798367142677\n",
            "Adjusting learning rate of group 0 to 8.1421e-08.\n",
            "0.037174202501773834\n",
            "Adjusting learning rate of group 0 to 8.1421e-08.\n",
            "0.037170495837926865\n",
            "Adjusting learning rate of group 0 to 8.1421e-08.\n",
            "0.037166714668273926\n",
            "Adjusting learning rate of group 0 to 8.1421e-08.\n",
            "0.03716297820210457\n",
            "Adjusting learning rate of group 0 to 8.1421e-08.\n",
            "0.03715920075774193\n",
            "Adjusting learning rate of group 0 to 8.1421e-08.\n",
            "0.0371553897857666\n",
            "Adjusting learning rate of group 0 to 8.1421e-08.\n",
            "0.037151604890823364\n",
            "Adjusting learning rate of group 0 to 8.1421e-08.\n",
            "0.03714784234762192\n",
            "Adjusting learning rate of group 0 to 8.1421e-08.\n",
            "0.03714408725500107\n",
            "Adjusting learning rate of group 0 to 8.1421e-08.\n",
            "0.03714021295309067\n",
            "Adjusting learning rate of group 0 to 8.1421e-08.\n",
            "0.037136420607566833\n",
            "Adjusting learning rate of group 0 to 8.1421e-08.\n",
            "0.03713258355855942\n",
            "Adjusting learning rate of group 0 to 5.6994e-08.\n",
            "0.037128761410713196\n",
            "Adjusting learning rate of group 0 to 5.6994e-08.\n",
            "0.03712495416402817\n",
            "Adjusting learning rate of group 0 to 5.6994e-08.\n",
            "0.037122249603271484\n",
            "Adjusting learning rate of group 0 to 5.6994e-08.\n",
            "0.037119537591934204\n",
            "Adjusting learning rate of group 0 to 5.6994e-08.\n",
            "0.037116892635822296\n",
            "Adjusting learning rate of group 0 to 5.6994e-08.\n",
            "0.037114132195711136\n",
            "Adjusting learning rate of group 0 to 5.6994e-08.\n",
            "0.03711147978901863\n",
            "Adjusting learning rate of group 0 to 5.6994e-08.\n",
            "0.03710875287652016\n",
            "Adjusting learning rate of group 0 to 5.6994e-08.\n",
            "0.037106048315763474\n",
            "Adjusting learning rate of group 0 to 5.6994e-08.\n",
            "0.037103381007909775\n",
            "Adjusting learning rate of group 0 to 5.6994e-08.\n",
            "0.03710061311721802\n",
            "Adjusting learning rate of group 0 to 5.6994e-08.\n",
            "0.03709793463349342\n",
            "Adjusting learning rate of group 0 to 5.6994e-08.\n",
            "0.037095196545124054\n",
            "Adjusting learning rate of group 0 to 5.6994e-08.\n",
            "0.03709246963262558\n",
            "Adjusting learning rate of group 0 to 5.6994e-08.\n",
            "0.03708966448903084\n",
            "Adjusting learning rate of group 0 to 3.9896e-08.\n",
            "0.03708694130182266\n",
            "Adjusting learning rate of group 0 to 3.9896e-08.\n",
            "0.03708421811461449\n",
            "Adjusting learning rate of group 0 to 3.9896e-08.\n",
            "0.03708227351307869\n",
            "Adjusting learning rate of group 0 to 3.9896e-08.\n",
            "0.03708037734031677\n",
            "Adjusting learning rate of group 0 to 3.9896e-08.\n",
            "0.03707846626639366\n",
            "Adjusting learning rate of group 0 to 3.9896e-08.\n",
            "0.03707648441195488\n",
            "Adjusting learning rate of group 0 to 3.9896e-08.\n",
            "0.03707452863454819\n",
            "Adjusting learning rate of group 0 to 3.9896e-08.\n",
            "0.03707261011004448\n",
            "Adjusting learning rate of group 0 to 3.9896e-08.\n",
            "0.03707069158554077\n",
            "Adjusting learning rate of group 0 to 3.9896e-08.\n",
            "0.03706871718168259\n",
            "Adjusting learning rate of group 0 to 3.9896e-08.\n",
            "0.03706676885485649\n",
            "Adjusting learning rate of group 0 to 3.9896e-08.\n",
            "0.03706483915448189\n",
            "Adjusting learning rate of group 0 to 3.9896e-08.\n",
            "0.03706291690468788\n",
            "Adjusting learning rate of group 0 to 3.9896e-08.\n",
            "0.0370609275996685\n",
            "Adjusting learning rate of group 0 to 3.9896e-08.\n",
            "0.037058934569358826\n",
            "Adjusting learning rate of group 0 to 2.7927e-08.\n",
            "0.03705698251724243\n",
            "Adjusting learning rate of group 0 to 2.7927e-08.\n",
            "0.03705504536628723\n",
            "Adjusting learning rate of group 0 to 2.7927e-08.\n",
            "0.037053659558296204\n",
            "Adjusting learning rate of group 0 to 2.7927e-08.\n",
            "0.03705231472849846\n",
            "Adjusting learning rate of group 0 to 2.7927e-08.\n",
            "0.037050940096378326\n",
            "Adjusting learning rate of group 0 to 2.7927e-08.\n",
            "0.03704956918954849\n",
            "Adjusting learning rate of group 0 to 2.7927e-08.\n",
            "0.037048179656267166\n",
            "Adjusting learning rate of group 0 to 2.7927e-08.\n",
            "0.03704676404595375\n",
            "Adjusting learning rate of group 0 to 2.7927e-08.\n",
            "0.0370454266667366\n",
            "Adjusting learning rate of group 0 to 2.7927e-08.\n",
            "0.037044014781713486\n",
            "Adjusting learning rate of group 0 to 2.7927e-08.\n",
            "0.03704269975423813\n",
            "Adjusting learning rate of group 0 to 2.7927e-08.\n",
            "0.037041258066892624\n",
            "Adjusting learning rate of group 0 to 2.7927e-08.\n",
            "0.037039853632450104\n",
            "Adjusting learning rate of group 0 to 2.7927e-08.\n",
            "0.03703845664858818\n",
            "Adjusting learning rate of group 0 to 2.7927e-08.\n",
            "0.03703705221414566\n",
            "Adjusting learning rate of group 0 to 1.9549e-08.\n",
            "0.03703565150499344\n",
            "Adjusting learning rate of group 0 to 1.9549e-08.\n",
            "0.03703426942229271\n",
            "Adjusting learning rate of group 0 to 1.9549e-08.\n",
            "0.0370333194732666\n",
            "Adjusting learning rate of group 0 to 1.9549e-08.\n",
            "0.037032321095466614\n",
            "Adjusting learning rate of group 0 to 1.9549e-08.\n",
            "0.03703135624527931\n",
            "Adjusting learning rate of group 0 to 1.9549e-08.\n",
            "0.03703037649393082\n",
            "Adjusting learning rate of group 0 to 1.9549e-08.\n",
            "0.0370294563472271\n",
            "Adjusting learning rate of group 0 to 1.9549e-08.\n",
            "0.03702843561768532\n",
            "Adjusting learning rate of group 0 to 1.9549e-08.\n",
            "0.03702749311923981\n",
            "Adjusting learning rate of group 0 to 1.9549e-08.\n",
            "0.037026502192020416\n",
            "Adjusting learning rate of group 0 to 1.9549e-08.\n",
            "0.03702549636363983\n",
            "Adjusting learning rate of group 0 to 1.9549e-08.\n",
            "0.03702451288700104\n",
            "Adjusting learning rate of group 0 to 1.9549e-08.\n",
            "0.037023503333330154\n",
            "Adjusting learning rate of group 0 to 1.9549e-08.\n",
            "0.03702256456017494\n",
            "Adjusting learning rate of group 0 to 1.9549e-08.\n",
            "0.037021536380052567\n",
            "Adjusting learning rate of group 0 to 1.3684e-08.\n",
            "0.03702060878276825\n",
            "Adjusting learning rate of group 0 to 1.3684e-08.\n",
            "0.03701961040496826\n",
            "Adjusting learning rate of group 0 to 1.3684e-08.\n",
            "0.037018924951553345\n",
            "Adjusting learning rate of group 0 to 1.3684e-08.\n",
            "0.03701819106936455\n",
            "Adjusting learning rate of group 0 to 1.3684e-08.\n",
            "0.03701748326420784\n",
            "Adjusting learning rate of group 0 to 1.3684e-08.\n",
            "0.03701682388782501\n",
            "Adjusting learning rate of group 0 to 1.3684e-08.\n",
            "0.03701615706086159\n",
            "Adjusting learning rate of group 0 to 1.3684e-08.\n",
            "0.03701547533273697\n",
            "Adjusting learning rate of group 0 to 1.3684e-08.\n",
            "0.037014786154031754\n",
            "Adjusting learning rate of group 0 to 1.3684e-08.\n",
            "0.03701413422822952\n",
            "Adjusting learning rate of group 0 to 1.3684e-08.\n",
            "0.03701339662075043\n",
            "Adjusting learning rate of group 0 to 1.3684e-08.\n",
            "0.03701268509030342\n",
            "Adjusting learning rate of group 0 to 1.3684e-08.\n",
            "0.03701202571392059\n",
            "Adjusting learning rate of group 0 to 1.3684e-08.\n",
            "0.03701133280992508\n",
            "Adjusting learning rate of group 0 to 1.3684e-08.\n",
            "0.03701063618063927\n",
            "Adjusting learning rate of group 0 to 9.5791e-09.\n",
            "0.037009913474321365\n",
            "Adjusting learning rate of group 0 to 9.5791e-09.\n",
            "0.037009239196777344\n",
            "Adjusting learning rate of group 0 to 9.5791e-09.\n",
            "0.037008777260780334\n",
            "Adjusting learning rate of group 0 to 9.5791e-09.\n",
            "0.03700829669833183\n",
            "Adjusting learning rate of group 0 to 9.5791e-09.\n",
            "0.037007831037044525\n",
            "Adjusting learning rate of group 0 to 9.5791e-09.\n",
            "0.03700731322169304\n",
            "Adjusting learning rate of group 0 to 9.5791e-09.\n",
            "0.03700684383511543\n",
            "Adjusting learning rate of group 0 to 9.5791e-09.\n",
            "0.037006378173828125\n",
            "Adjusting learning rate of group 0 to 9.5791e-09.\n",
            "0.03700587525963783\n",
            "Adjusting learning rate of group 0 to 9.5791e-09.\n",
            "0.03700536862015724\n",
            "Adjusting learning rate of group 0 to 9.5791e-09.\n",
            "0.03700494393706322\n",
            "Adjusting learning rate of group 0 to 9.5791e-09.\n",
            "0.03700444474816322\n",
            "Adjusting learning rate of group 0 to 9.5791e-09.\n",
            "0.03700397163629532\n",
            "Adjusting learning rate of group 0 to 9.5791e-09.\n",
            "0.03700349107384682\n",
            "Adjusting learning rate of group 0 to 9.5791e-09.\n",
            "0.03700300678610802\n",
            "Adjusting learning rate of group 0 to 6.7053e-09.\n",
            "0.037002503871917725\n",
            "Adjusting learning rate of group 0 to 6.7053e-09.\n",
            "0.03700203448534012\n",
            "Adjusting learning rate of group 0 to 6.7053e-09.\n",
            "0.03700167313218117\n",
            "Adjusting learning rate of group 0 to 6.7053e-09.\n",
            "0.037001367658376694\n",
            "Adjusting learning rate of group 0 to 6.7053e-09.\n",
            "0.03700100630521774\n",
            "Adjusting learning rate of group 0 to 6.7053e-09.\n",
            "0.03700069710612297\n",
            "Adjusting learning rate of group 0 to 6.7053e-09.\n",
            "0.03700035810470581\n",
            "Adjusting learning rate of group 0 to 6.7053e-09.\n",
            "0.03700002282857895\n",
            "Adjusting learning rate of group 0 to 6.7053e-09.\n",
            "0.03699970617890358\n",
            "Adjusting learning rate of group 0 to 6.7053e-09.\n",
            "0.03699938952922821\n",
            "Adjusting learning rate of group 0 to 6.7053e-09.\n",
            "0.03699908033013344\n",
            "Adjusting learning rate of group 0 to 6.7053e-09.\n",
            "0.03699874132871628\n",
            "Adjusting learning rate of group 0 to 6.7053e-09.\n",
            "0.03699835017323494\n",
            "Adjusting learning rate of group 0 to 6.7053e-09.\n",
            "0.036998067051172256\n",
            "Adjusting learning rate of group 0 to 6.7053e-09.\n",
            "0.03699769452214241\n",
            "Adjusting learning rate of group 0 to 4.6937e-09.\n",
            "0.036997418850660324\n",
            "Adjusting learning rate of group 0 to 4.6937e-09.\n",
            "0.03699703887104988\n",
            "Adjusting learning rate of group 0 to 4.6937e-09.\n",
            "0.03699683025479317\n",
            "Adjusting learning rate of group 0 to 4.6937e-09.\n",
            "0.03699660673737526\n",
            "Adjusting learning rate of group 0 to 4.6937e-09.\n",
            "0.036996353417634964\n",
            "Adjusting learning rate of group 0 to 4.6937e-09.\n",
            "0.036996111273765564\n",
            "Adjusting learning rate of group 0 to 4.6937e-09.\n",
            "0.03699588030576706\n",
            "Adjusting learning rate of group 0 to 4.6937e-09.\n",
            "0.03699573874473572\n",
            "Adjusting learning rate of group 0 to 4.6937e-09.\n",
            "0.036995500326156616\n",
            "Adjusting learning rate of group 0 to 4.6937e-09.\n",
            "0.03699522465467453\n",
            "Adjusting learning rate of group 0 to 4.6937e-09.\n",
            "0.036995045840740204\n",
            "Adjusting learning rate of group 0 to 4.6937e-09.\n",
            "0.036994848400354385\n",
            "Adjusting learning rate of group 0 to 4.6937e-09.\n",
            "0.03699452802538872\n",
            "Adjusting learning rate of group 0 to 4.6937e-09.\n",
            "0.0369943305850029\n",
            "Adjusting learning rate of group 0 to 4.6937e-09.\n",
            "0.03699412941932678\n",
            "Adjusting learning rate of group 0 to 3.2856e-09.\n",
            "0.036993931978940964\n",
            "Adjusting learning rate of group 0 to 3.2856e-09.\n",
            "0.03699367493391037\n",
            "Adjusting learning rate of group 0 to 3.2856e-09.\n",
            "0.03699345141649246\n",
            "Adjusting learning rate of group 0 to 3.2856e-09.\n",
            "0.036993369460105896\n",
            "Adjusting learning rate of group 0 to 3.2856e-09.\n",
            "0.03699316829442978\n",
            "Adjusting learning rate of group 0 to 3.2856e-09.\n",
            "0.03699301555752754\n",
            "Adjusting learning rate of group 0 to 3.2856e-09.\n",
            "0.0369928739964962\n",
            "Adjusting learning rate of group 0 to 3.2856e-09.\n",
            "0.03699271380901337\n",
            "Adjusting learning rate of group 0 to 3.2856e-09.\n",
            "0.036992549896240234\n",
            "Adjusting learning rate of group 0 to 3.2856e-09.\n",
            "0.03699241951107979\n",
            "Adjusting learning rate of group 0 to 3.2856e-09.\n",
            "0.036992255598306656\n",
            "Adjusting learning rate of group 0 to 3.2856e-09.\n",
            "0.036992136389017105\n",
            "Adjusting learning rate of group 0 to 3.2856e-09.\n",
            "0.036991965025663376\n",
            "Adjusting learning rate of group 0 to 3.2856e-09.\n",
            "0.036991801112890244\n",
            "Adjusting learning rate of group 0 to 3.2856e-09.\n",
            "0.03699161857366562\n",
            "Adjusting learning rate of group 0 to 2.2999e-09.\n",
            "0.03699147328734398\n",
            "Adjusting learning rate of group 0 to 2.2999e-09.\n",
            "0.036991339176893234\n",
            "Adjusting learning rate of group 0 to 2.2999e-09.\n",
            "0.03699124976992607\n",
            "Adjusting learning rate of group 0 to 2.2999e-09.\n",
            "0.036991119384765625\n",
            "Adjusting learning rate of group 0 to 2.2999e-09.\n",
            "0.03699103742837906\n",
            "Adjusting learning rate of group 0 to 2.2999e-09.\n",
            "0.036990951746702194\n",
            "Adjusting learning rate of group 0 to 2.2999e-09.\n",
            "0.03699084371328354\n",
            "Adjusting learning rate of group 0 to 2.2999e-09.\n",
            "0.03699076548218727\n",
            "Adjusting learning rate of group 0 to 2.2999e-09.\n",
            "0.036990679800510406\n",
            "Adjusting learning rate of group 0 to 2.2999e-09.\n",
            "0.03699057176709175\n",
            "Adjusting learning rate of group 0 to 2.2999e-09.\n",
            "0.036990486085414886\n",
            "Adjusting learning rate of group 0 to 2.2999e-09.\n",
            "0.036990322172641754\n",
            "Adjusting learning rate of group 0 to 2.2999e-09.\n",
            "0.03699023649096489\n",
            "Adjusting learning rate of group 0 to 2.2999e-09.\n",
            "0.03699016198515892\n",
            "Adjusting learning rate of group 0 to 2.2999e-09.\n",
            "0.036990031599998474\n",
            "Adjusting learning rate of group 0 to 1.6100e-09.\n",
            "0.036989908665418625\n",
            "Adjusting learning rate of group 0 to 1.6100e-09.\n",
            "0.03698984533548355\n",
            "Adjusting learning rate of group 0 to 1.6100e-09.\n",
            "0.036989785730838776\n",
            "Adjusting learning rate of group 0 to 1.6100e-09.\n",
            "0.036989726126194\n",
            "Adjusting learning rate of group 0 to 1.6100e-09.\n",
            "0.03698968142271042\n",
            "Adjusting learning rate of group 0 to 1.6100e-09.\n",
            "0.03698962926864624\n",
            "Adjusting learning rate of group 0 to 1.6100e-09.\n",
            "0.03698953241109848\n",
            "Adjusting learning rate of group 0 to 1.6100e-09.\n",
            "0.036989521235227585\n",
            "Adjusting learning rate of group 0 to 1.6100e-09.\n",
            "0.03698943555355072\n",
            "Adjusting learning rate of group 0 to 1.6100e-09.\n",
            "0.03698938712477684\n",
            "Adjusting learning rate of group 0 to 1.6100e-09.\n",
            "0.03698929771780968\n",
            "Adjusting learning rate of group 0 to 1.6100e-09.\n",
            "0.03698926046490669\n",
            "Adjusting learning rate of group 0 to 1.6100e-09.\n",
            "0.036989208310842514\n",
            "Adjusting learning rate of group 0 to 1.6100e-09.\n",
            "0.03698914498090744\n",
            "Adjusting learning rate of group 0 to 1.6100e-09.\n",
            "0.03698902949690819\n",
            "Adjusting learning rate of group 0 to 1.1270e-09.\n",
            "0.03698896989226341\n",
            "Adjusting learning rate of group 0 to 1.1270e-09.\n",
            "0.03698893263936043\n",
            "Adjusting learning rate of group 0 to 1.1270e-09.\n",
            "0.036988891661167145\n",
            "Adjusting learning rate of group 0 to 1.1270e-09.\n",
            "0.03698885813355446\n",
            "Adjusting learning rate of group 0 to 1.1270e-09.\n",
            "0.036988817155361176\n",
            "Adjusting learning rate of group 0 to 1.1270e-09.\n",
            "0.03698877990245819\n",
            "Adjusting learning rate of group 0 to 1.1270e-09.\n",
            "0.036988694220781326\n",
            "Adjusting learning rate of group 0 to 1.1270e-09.\n",
            "0.03698865696787834\n",
            "Adjusting learning rate of group 0 to 1.1270e-09.\n",
            "0.036988597363233566\n",
            "Adjusting learning rate of group 0 to 1.1270e-09.\n",
            "0.036988552659749985\n",
            "Adjusting learning rate of group 0 to 1.1270e-09.\n",
            "0.0369885191321373\n",
            "Adjusting learning rate of group 0 to 1.1270e-09.\n",
            "0.03698847442865372\n",
            "Adjusting learning rate of group 0 to 1.1270e-09.\n",
            "0.03698843717575073\n",
            "Adjusting learning rate of group 0 to 1.1270e-09.\n",
            "0.036988403648138046\n",
            "Adjusting learning rate of group 0 to 1.1270e-09.\n",
            "0.036988355219364166\n",
            "Adjusting learning rate of group 0 to 7.8888e-10.\n",
            "0.03698832914233208\n",
            "Adjusting learning rate of group 0 to 7.8888e-10.\n",
            "0.03698829561471939\n",
            "Adjusting learning rate of group 0 to 7.8888e-10.\n",
            "0.0369882695376873\n",
            "Adjusting learning rate of group 0 to 7.8888e-10.\n",
            "0.036988258361816406\n",
            "Adjusting learning rate of group 0 to 7.8888e-10.\n",
            "0.036988236010074615\n",
            "Adjusting learning rate of group 0 to 7.8888e-10.\n",
            "0.036988213658332825\n",
            "Adjusting learning rate of group 0 to 7.8888e-10.\n",
            "0.03698817640542984\n",
            "Adjusting learning rate of group 0 to 7.8888e-10.\n",
            "0.03698813170194626\n",
            "Adjusting learning rate of group 0 to 7.8888e-10.\n",
            "0.03698810562491417\n",
            "Adjusting learning rate of group 0 to 7.8888e-10.\n",
            "0.03698807954788208\n",
            "Adjusting learning rate of group 0 to 7.8888e-10.\n",
            "0.03698805719614029\n",
            "Adjusting learning rate of group 0 to 7.8888e-10.\n",
            "0.0369880236685276\n",
            "Adjusting learning rate of group 0 to 7.8888e-10.\n",
            "0.036987997591495514\n",
            "Adjusting learning rate of group 0 to 7.8888e-10.\n",
            "0.03698799014091492\n",
            "Adjusting learning rate of group 0 to 7.8888e-10.\n",
            "0.03698798269033432\n",
            "Adjusting learning rate of group 0 to 5.5221e-10.\n",
            "0.03698793053627014\n",
            "Adjusting learning rate of group 0 to 5.5221e-10.\n",
            "0.03698790818452835\n",
            "Adjusting learning rate of group 0 to 5.5221e-10.\n",
            "0.03698788955807686\n",
            "Adjusting learning rate of group 0 to 5.5221e-10.\n",
            "0.036987870931625366\n",
            "Adjusting learning rate of group 0 to 5.5221e-10.\n",
            "0.03698785603046417\n",
            "Adjusting learning rate of group 0 to 5.5221e-10.\n",
            "0.03698783740401268\n",
            "Adjusting learning rate of group 0 to 5.5221e-10.\n",
            "0.03698784112930298\n",
            "Adjusting learning rate of group 0 to 5.5221e-10.\n",
            "0.036987803876399994\n",
            "Adjusting learning rate of group 0 to 5.5221e-10.\n",
            "0.0369877889752388\n",
            "Adjusting learning rate of group 0 to 5.5221e-10.\n",
            "0.03698776662349701\n",
            "Adjusting learning rate of group 0 to 5.5221e-10.\n",
            "0.03698774799704552\n",
            "Adjusting learning rate of group 0 to 5.5221e-10.\n",
            "0.03698773309588432\n",
            "Adjusting learning rate of group 0 to 5.5221e-10.\n",
            "0.03698771819472313\n",
            "Adjusting learning rate of group 0 to 5.5221e-10.\n",
            "0.03698769956827164\n",
            "Adjusting learning rate of group 0 to 5.5221e-10.\n",
            "0.03698769584298134\n",
            "Adjusting learning rate of group 0 to 3.8655e-10.\n",
            "0.036987677216529846\n",
            "Adjusting learning rate of group 0 to 3.8655e-10.\n",
            "0.03698766231536865\n",
            "Adjusting learning rate of group 0 to 3.8655e-10.\n",
            "0.03698762506246567\n",
            "Adjusting learning rate of group 0 to 3.8655e-10.\n",
            "0.03698763996362686\n",
            "Adjusting learning rate of group 0 to 3.8655e-10.\n",
            "0.036987606436014175\n",
            "Adjusting learning rate of group 0 to 3.8655e-10.\n",
            "0.03698759526014328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#quick output\n",
        "!pip install --quiet SimpleITK\n",
        "import SimpleITK as sitk"
      ],
      "metadata": {
        "id": "WlSltURt0GFq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2afd497d-112e-4b3e-baec-73fddd1a7c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = sitk.GetImageFromArray(np.where(torch.sigmoid(batched_output[0]['logits'][1, 0]).cpu().detach().numpy() > 0.5, 1, 0))\n",
        "image = sitk.Cast(image, sitk.sitkUInt32)\n",
        "sitk.WriteImage(image, '/content/temp.nii.gz')"
      ],
      "metadata": {
        "id": "7cJ0WjcuCj9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = sitk.GetImageFromArray(mask_inputs[1, 0].cpu().detach().numpy())\n",
        "image = sitk.Cast(image, sitk.sitkUInt32)\n",
        "sitk.WriteImage(image, '/content/temp_mask.nii.gz')"
      ],
      "metadata": {
        "id": "5790NATs4WWe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}